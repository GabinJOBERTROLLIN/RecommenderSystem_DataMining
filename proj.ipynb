{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation of libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image, ExifTags\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import Perceptron\n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Getting a Json with Wikidata Query\n",
    "We created a WikiData Query to request a Json file, containing the links to open-licensed images. We used images with different themes:<br>\n",
    "\n",
    "fruit = Q1364<br>\n",
    "Dog = Q144<br>\n",
    "lake  = Q23397<br>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SELECT ?image ?im WHERE {\n",
    "  ?image wdt:P31 wd:Q506.\n",
    "  ?image wdt:P18 ?im\n",
    "  }\n",
    "LIMIT 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'head': {'vars': ['image', 'im']}, 'results': {'bindings': [{'image': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q316011'}, 'im': {'type': 'uri', 'value': 'http://commons.wikimedia.org/wiki/Special:FilePath/Brewster%20Lake%20Sayward%20Forest%20Canoe%20Route.jpg'}, 'tag': 'Lake'}, {'image': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q316028'}, 'im': {'type': 'uri', 'value': 'http://commons.wikimedia.org/wiki/Special:FilePath/Dobbertiner%20See%20und%20Kloster.jpg'}, 'tag': 'Lake'}, {'image': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q316044'}, 'im': {'type': 'uri', 'value': 'http://commons.wikimedia.org/wiki/Special:FilePath/Goldberg%20Goldberger%20See%20Badestrand%202012-03-23%20511.JPG'}, 'tag': 'Lake'}, {'image': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q316177'}, 'im': {'type': 'uri', 'value': 'http://commons.wikimedia.org/wiki/Special:FilePath/Emerald%20Lake-Yoho.jpg'}, 'tag': 'Lake'}, {'image': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q316181'}, 'im': {'type': 'uri', 'value': 'http://commons.wikimedia.org/wiki/Special:FilePath/Howard%20Lake.JPG'}, 'tag': 'Lake'}]}}\n"
     ]
    }
   ],
   "source": [
    "lstSources = {\"Fruit\":1364,\"Dog\":144,\"Lake\":23397} #Sources from which we download the images\n",
    "limitPerSources = 5\n",
    "sources = {}\n",
    "tagTemp = []\n",
    "for key,value in lstSources.items():    #Get all images to download\n",
    "    url =\"https://query.wikidata.org/sparql?query=SELECT%20%3Fimage%20%3Fim%20WHERE%20%7B%0A%20%20%3Fimage%20wdt%3AP31%20wd%3AQ\"+str(value)+\".%0A%20%20%3Fimage%20wdt%3AP18%20%3Fim%0A%20%20%7D%0ALIMIT%20\"+str(limitPerSources)+\"&format=json\"\n",
    "    response = urllib.request.urlopen(url)\n",
    "    myJson = json.loads(response.read().decode(\"utf-8\"))\n",
    "    \n",
    "    for image in myJson[\"results\"][\"bindings\"]:  #Add the tag to the image\n",
    "        image['tag'] = key\n",
    "        \n",
    "    if sources == {}:   #Make one big json containing all images information\n",
    "        sources = myJson\n",
    "    else:\n",
    "        sources[\"results\"][\"bindings\"] = sources[\"results\"][\"bindings\"]+myJson[\"results\"][\"bindings\"]\n",
    "\n",
    "myJsonNormalized = pd.json_normalize(sources)\n",
    "print(myJson)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Télechargement des images ##\n",
    "A partir du Json contenant les liens menant aux images, nous lancons des requètes URLLIB pour télecharger ces images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading images\n",
    "\n",
    "responseJson = myJsonNormalized[\"results.bindings\"]\n",
    "index=0\n",
    "lstTag=[]\n",
    "for i in range(len(responseJson[0])):   \n",
    "    # Getting image Link for each image\n",
    "    imageLink = responseJson[0][i][\"im\"][\"value\"]\n",
    "    lstTag.append(responseJson[0][i][\"tag\"])\n",
    "    \n",
    "    # Requesting to Download images and saving it as \"images$.jpg\" where $ is the image id\n",
    "    im = \"./images/image\"+str(index)+\".jpg\"\n",
    "    urllib.request.urlretrieve(imageLink, im)\n",
    "    index +=1\n",
    "\n",
    "    #Convert images to RGB, to prevent future errors\n",
    "    try:\n",
    "        imgfile = Image.open(im).convert(\"RGB\")\n",
    "    except:\n",
    "        index-=1\n",
    "        del lstTag[-1]\n",
    "        print(\"pas fonctionne\")\n",
    "    \n",
    "NOMBRE_IMAGE=index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Récupération des métadonnées\n",
    "L'obhectif de cette partie est de récupérer les informations des images, nous récupérons les images suivantes :<br>\n",
    "1. Récupération Exif utiles\n",
    "2. Récupération couleurs dominantes (K-means)\n",
    "3. Récupération taille des images\n",
    "4. Détermination portrait ou paysage\n",
    "\n",
    "Apres cela, nous avons creer un Json **metaDataJson.json** contenant toutes les informationns precedentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gabin\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:887: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 4096 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n",
      "c:\\Users\\gabin\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:887: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 4096 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n",
      "c:\\Users\\gabin\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:887: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 4096 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n",
      "c:\\Users\\gabin\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:887: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 4096 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n",
      "c:\\Users\\gabin\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:887: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 4096 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n",
      "c:\\Users\\gabin\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:887: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 4096 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n",
      "c:\\Users\\gabin\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:887: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 4096 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n",
      "c:\\Users\\gabin\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:887: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 4096 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n",
      "c:\\Users\\gabin\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:887: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 4096 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n",
      "c:\\Users\\gabin\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:887: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 4096 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n",
      "c:\\Users\\gabin\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:887: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 4096 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n",
      "c:\\Users\\gabin\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:887: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 4096 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n",
      "c:\\Users\\gabin\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:887: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 4096 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n",
      "c:\\Users\\gabin\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:887: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 4096 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n",
      "c:\\Users\\gabin\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:887: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 4096 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Collecting meta-data\n",
    "\n",
    "metaData ={}\n",
    "for i in range(NOMBRE_IMAGE):\n",
    "    im = \"./images/image\"+str(i)+\".jpg\"\n",
    "    try:\n",
    "        imgfile = Image.open(im).convert(\"RGB\")\n",
    "\n",
    "        # selecting the useful Exif\n",
    "        exif = {}\n",
    "        exifCritere= (\"Model\",\"Make\",\"ImageDescription\",\"ExposureTime\",\"GPSInfo\",\"ISO\",\"DateTimeOriginal\")\n",
    "        for k,v in  imgfile.getexif().items() :\n",
    "            if k in ExifTags.TAGS :\n",
    "                if ExifTags.TAGS[k] in exifCritere:\n",
    "                    exif = {ExifTags.TAGS[k]:v}\n",
    "\n",
    "        # Collecting 3 predominant colors (using K-means)\n",
    "        numarray = np.array(imgfile.getdata(), np.uint8)\n",
    "        clusters  = MiniBatchKMeans(n_clusters=3, n_init=2) \n",
    "        clusters.fit(numarray)\n",
    "        L = clusters.cluster_centers_.astype(int).tolist()\n",
    "\n",
    "        # Really simply setting the dominant color using the value of the most present color in the image\n",
    "        if L[0][0]>L[0][1] and L[0][0]>L[0][2]:\n",
    "            domColor = \"Red\"\n",
    "        elif L[0][1]>L[0][0] and L[0][1]>L[0][2]:\n",
    "            domColor = \"Green\"\n",
    "        elif L[0][2]>L[0][0] and L[0][2]>L[0][1]:\n",
    "            domColor = \"Blue\"\n",
    "        elif L[0][0]==L[0][1]==L[0][2]:\n",
    "            domColor = \"White\"\n",
    "        else:\n",
    "            domColor = \"None\"\n",
    "\n",
    "        # Collecting images sizez\n",
    "        width = imgfile.width\n",
    "        height = imgfile.height\n",
    "        mode = imgfile.mode\n",
    "\n",
    "        # identify image orientation\n",
    "        if abs(1-width/height)<0.1 :\n",
    "            orientation='carre' \n",
    "        elif width>height:\n",
    "            orientation='paysage'\n",
    "        else: \n",
    "            orientation=\"portrait\"\n",
    "\n",
    "        # Get image size (big, small, ...)\n",
    "        pixelCount = width * height\n",
    "\n",
    "        if pixelCount >= 1920*1080:\n",
    "            size = \"Grande\"\n",
    "        elif pixelCount >= 1280*720:\n",
    "            size = \"Moyenne\"\n",
    "        elif pixelCount >= 720*480:\n",
    "            size = \"Petite\"\n",
    "        elif pixelCount < 720*480:\n",
    "            size = \"Vignette\"\n",
    "        else:\n",
    "            size = \"WTF\"\n",
    "\n",
    "        metaData[\"image\"+str(i)] = { \"width\" : width, \"height\": height, \"exif\": exif, \"mode\":mode, \"tags\":[lstTag[i]], \"couleurs\":L, \"orientation\":orientation, \"size\":size, \"dom\":domColor}\n",
    "    except Exception:\n",
    "        print(\"l'image \"+str(i) +\" ne peut pas etre ouverte\")\n",
    "metaData\n",
    "\n",
    "metaDatajson = json.dumps(metaData)\n",
    "f = open(\"metaDataJson.json\", \"w\")\n",
    "f.write(metaDatajson)\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis\n",
    "Consist of 2 parts :\n",
    "1. The first one  color analysis to get if an image has a colors patern close to mages previously liked image by the user. Then we feed it to a more global analysis.\n",
    "2. The global analysis, use a decision tree classifier to analyse the data in our user database, and the result of our color analyses, and predict if an image is likely to be liked by the user.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(L):\n",
    "# INPUT     : L (List)\n",
    "# OUTPUT    : Flattened version of L\n",
    "# DESCRIPTION : return a flattened version of the input list \"L\" : [[1,2,3],[1,2]] -> [1,2,3,1,2]\n",
    "    return [item for sublist in L for item in sublist]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def analyseCouleur(nameUser,nomImage): \n",
    "# INPUT     : numUser (user ID as an integer ex:1)\n",
    "#           : nomImage (the name in metadatajson.json of the image to predictas a string ex:\"image0\")\n",
    "# OUTPUT    : y_predict[0] (an integer either 0 if the algorithm precict the user won't like the image\n",
    "#             or 1 if the image is predicted to be liked)\n",
    "# DESCRIPTION : predict if an user will liked an image, based solely on the image color mathing previous images\n",
    "\n",
    "\n",
    "    couleurs = []\n",
    "    jsonUserDF=pd.read_json(\"jsonUser.json\")\n",
    "    jsonMetaDF=pd.read_json(\"metaDataJson.json\")\n",
    "    #userId=\"user\"+str(numUser)\n",
    "\n",
    "    for image in jsonUserDF[nameUser][\"images\"]:\n",
    "        couleurs.append(flatten(jsonMetaDF[image][\"couleurs\"]))\n",
    "        \n",
    "    # creating training the model with what the user have already seen\n",
    "    numarray=np.array(couleurs)\n",
    "    like=np.array(jsonUserDF[nameUser][\"result\"])\n",
    "  \n",
    "    percep = Perceptron(max_iter=1000)\n",
    "    percep.fit(numarray, like)\n",
    "\n",
    "\n",
    "    # predicting if the use would like the input image\n",
    "    x_predict = np.array([flatten(jsonMetaDF[nomImage][\"couleurs\"])])\n",
    "    y_predict = percep.predict(x_predict)\n",
    "\n",
    "    return y_predict[0]\n",
    "\n",
    "# exemple to test the function by itself:\n",
    "# analyseCouleur(\"user1\",\"image1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-88d02f469002>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;31m#TODO Vérifier que likedColor pas toujours le seul critère déterminant\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m \u001b[0manalyseGlobal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"user4\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"image8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-88d02f469002>\u001b[0m in \u001b[0;36manalyseGlobal\u001b[1;34m(nameUser, nomImage)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mle1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOrdinalEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle_unknown\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'use_encoded_value'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munknown_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[0mdataframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"dom\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mle1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"dom\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[0mle2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOrdinalEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle_unknown\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'use_encoded_value'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munknown_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\gabin\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    697\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\gabin\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    759\u001b[0m                             f\"got {self.unknown_value}.\")\n\u001b[0;32m    760\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 761\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    762\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle_unknown\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'use_encoded_value'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\gabin\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, handle_unknown, force_all_finite)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         X_list, n_samples, n_features = self._check_X(\n\u001b[0m\u001b[0;32m     78\u001b[0m             X, force_all_finite=force_all_finite)\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\gabin\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36m_check_X\u001b[1;34m(self, X, force_all_finite)\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'iloc'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ndim'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[1;31m# if not a dataframe, do normal check_array validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             X_temp = check_array(X, dtype=None,\n\u001b[0m\u001b[0;32m     45\u001b[0m                                  force_all_finite=force_all_finite)\n\u001b[0;32m     46\u001b[0m             if (not hasattr(X, 'dtype')\n",
      "\u001b[1;32mc:\\Users\\gabin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\gabin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 669\u001b[1;33m             raise ValueError(\"Found array with %d sample(s) (shape=%s) while a\"\n\u001b[0m\u001b[0;32m    670\u001b[0m                              \u001b[1;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m                              % (n_samples, array.shape, ensure_min_samples,\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "\n",
    "def analyseGlobal(nameUser,nomImage):\n",
    "    # INPUT     : nameUser (string), nomImage (string)\n",
    "    # OUTPUT    : prediction\n",
    "    # DESCRIPTION : returns whether the user should or shouldn't like the image (\"Favorite\" or \"NotFavorite\")\n",
    "\n",
    "    # Get image data\n",
    "    jsonMetaDF = pd.read_json(\"metaDataJson.json\")\n",
    "\n",
    "    # Get user like\n",
    "    userDF = pd.read_json(\"jsonUser.json\")\n",
    "    userImages = userDF.loc[\"images\"][nameUser]\n",
    "    userLike = userDF.loc[\"result\"][nameUser]\n",
    "\n",
    "    # Get data from the images already seen by the user for the training\n",
    "    data = []\n",
    "    for item in userImages:\n",
    "        imageDesc = []\n",
    "        imageDesc.append(jsonMetaDF.loc[\"dom\"][item])\n",
    "        imageDesc.append(jsonMetaDF.loc[\"tags\"][item][0])\n",
    "        imageDesc.append(jsonMetaDF.loc[\"size\"][item])\n",
    "        imageDesc.append(jsonMetaDF.loc[\"orientation\"][item])\n",
    "        imageDesc.append(analyseCouleur(nameUser,item))\n",
    "        data.append(imageDesc)\n",
    "\n",
    "    # Get whether the user liked or not the images for the training\n",
    "    result = [None]*len(userImages)\n",
    "    for item in jsonMetaDF:\n",
    "        if item in userImages:\n",
    "            ind = userImages.index(item)\n",
    "            if userLike[ind] == 1:\n",
    "                result[ind]=\"Favorite\"\n",
    "            else :\n",
    "                result[ind]=\"NotFavorite\"\n",
    "\n",
    "    # creating dataframes\n",
    "    dataframe = pd.DataFrame(data, columns=[\"dom\", \"tags\", \"size\", \"orientation\",\"likedColor\"])\n",
    "    resultframe = pd.DataFrame(result, columns=[\"favorite\"])\n",
    "\n",
    "    le1 = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "    dataframe[\"dom\"] = le1.fit_transform(dataframe[\"dom\"].values.reshape(-1,1))\n",
    "\n",
    "    le2 = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "    dataframe[\"tags\"] = le2.fit_transform(dataframe[\"tags\"].values.reshape(-1,1))\n",
    "\n",
    "    le3 = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "    dataframe[\"size\"] = le3.fit_transform(dataframe[\"size\"].values.reshape(-1,1))\n",
    "\n",
    "    le4 = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "    dataframe[\"orientation\"] = le4.fit_transform(dataframe[\"orientation\"].values.reshape(-1,1))\n",
    "\n",
    "    le5 = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "    dataframe[\"likedColor\"] = le5.fit_transform(dataframe[\"likedColor\"].values.reshape(-1,1))\n",
    "\n",
    "    le6 = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "    resultframe[\"favorite\"] = le6.fit_transform(resultframe[\"favorite\"].values.reshape(-1,1))\n",
    "    \n",
    "    # Use of decision tree classifiers\n",
    "    dtc = tree.DecisionTreeClassifier()\n",
    "    dtc = dtc.fit(dataframe.values, resultframe)\n",
    "\n",
    "\n",
    "    #prediction\n",
    "\n",
    "    # Get data from the image we want to predict\n",
    "    colorP = jsonMetaDF.loc[\"dom\"][nomImage]\n",
    "    tagsP = jsonMetaDF.loc[\"tags\"][nomImage]\n",
    "    sizeP = jsonMetaDF.loc[\"size\"][nomImage]\n",
    "    orientationP = jsonMetaDF.loc[\"orientation\"][nomImage]\n",
    "    colorLikeP = analyseCouleur(nameUser,nomImage)\n",
    "    \n",
    "    prediction = dtc.predict(np.array([\n",
    "        \n",
    "            le1.transform(pd.DataFrame([colorP], columns=[\"couleur\"]))[0],\n",
    "            le2.transform(pd.DataFrame([tagsP], columns=[\"tag\"]))[0],\n",
    "            le3.transform(pd.DataFrame([sizeP], columns=[\"size\"]))[0],\n",
    "            le4.transform(pd.DataFrame([orientationP], columns=[\"orientation\"]))[0],\n",
    "            le5.transform(pd.DataFrame([colorLikeP], columns=[\"likedColor\"]))[0],\n",
    "        \n",
    "    ]).reshape(1,-1))\n",
    "    \n",
    "    print(dtc.feature_importances_)\n",
    "    return le6.inverse_transform(prediction.reshape(-1,1)).tolist()[0][0]\n",
    "    \n",
    "#TODO Vérifier que likedColor pas toujours le seul critère déterminant\n",
    "analyseGlobal(\"user4\",\"image8\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Systeme de recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createUser(nom, prenom, images = None,like = None):\n",
    "# INPUT     : nom (User first name as a string)\n",
    "#           : prenom (User last name as a string)\n",
    "#           : images (OPTIONAL, a list of all images the user have already seen, ex:[image1,image2])\n",
    "#           : prenom (OPTIONAL, a list of 0 and 1, which corresponds to images, ex:[0,1] meaning the user only like the second image)\n",
    "# DESCRIPTION : Dcreate a new user in our user database (jsonUser.json), using name, last name, and already seen images as input\n",
    "\n",
    "\n",
    "    jsonUser=json.load(open(\"jsonUser.json\"))\n",
    "    userId=\"user\"+str(len(jsonUser))\n",
    "\n",
    "    # If optional arguments,like and images are not presented, set them at random\n",
    "    if images == None:\n",
    "        firstImage = \"image\" + str(random.randint(0,NOMBRE_IMAGE-1))\n",
    "        images = [firstImage]\n",
    "        like = [random.randint(0,1)]\n",
    "    \n",
    "    # Creating the json structure\n",
    "    if len(images) == len(like) :\n",
    "        jsonUser[userId]={\"nom\" : nom,\"prenom\" : prenom, \"images\":images,\"result\":like,\"year\":\"\",\"size\":\"\",\"tagFav\":\"\",\"orientation\":\"\",\"couleursFav\":\"\"}\n",
    "    else :\n",
    "        print(\"Please give image and like list of same size\")\n",
    "    \n",
    "    # Storing the structure in our database (jsonUser.json)\n",
    "    jsonUserStr = json.dumps(jsonUser, indent=4)\n",
    "    f = open(\"jsonUser.json\", \"w\")\n",
    "    f.write(jsonUserStr)\n",
    "    f.close()  \n",
    "createUser(\"Jean\", \"Paul\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['image0', 'image1', 'image2', 'image3', 'image4', 'image5', 'image6',\n",
      "       'image7', 'image8', 'image9', 'image10', 'image11', 'image12',\n",
      "       'image13', 'image14'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\gabin\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-7cdcea0f88ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mcyclePropositionImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"fruitEnjoyer\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[0mcyclePropositionImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"lakeEnjoyer\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m \u001b[0mtestNcycle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-7cdcea0f88ed>\u001b[0m in \u001b[0;36mtestNcycle\u001b[1;34m(N)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtestNcycle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m         \u001b[0mcyclePropositionImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m         \u001b[0mcyclePropositionImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"dogEnjoyer\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mcyclePropositionImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"fruitEnjoyer\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-7cdcea0f88ed>\u001b[0m in \u001b[0;36mcyclePropositionImage\u001b[1;34m(numUser, typeEnjoyer)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mjsonMetaKeys\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mjsonUserDF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muserId\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"images\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m             \u001b[0mana\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0manalyseGlobal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumUser\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mana\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Favorite'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m                 \u001b[0mimageDonee\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-88d02f469002>\u001b[0m in \u001b[0;36manalyseGlobal\u001b[1;34m(nameUser, nomImage)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mimageDesc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjsonMetaDF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"size\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mimageDesc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjsonMetaDF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"orientation\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mimageDesc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manalyseCouleur\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnameUser\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimageDesc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-f67cfa0c44a0>\u001b[0m in \u001b[0;36manalyseCouleur\u001b[1;34m(nameUser, nomImage)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m#userId=\"user\"+str(numUser)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mjsonUserDF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnameUser\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"images\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mcouleurs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjsonMetaDF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"couleurs\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\gabin\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3023\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3024\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3025\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\gabin\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "def demandeFavoriteOrNot(nomImage,typeEnjoyer=\"UserLikeImages\"):\n",
    "# INPUT     : nomImage (the name in metadatajson.json of the image to predictas a string ex:\"image0\")\n",
    "#           : typeEnjoyer (OPTIONAL, it is a test parameter to tell the machine to like every image with a specific tag)\n",
    "# OUTPUT    : 0(int) or 1(int) (0 means the user disliked the image, 1 the user liked)\n",
    "# DESCRIPTION : Provide the image to the user and asked if the user like it. If thhe Optional argument typeEnjoyer\n",
    "#             : is provided, it automatically fill the likes depending of the parameter value.\n",
    "\n",
    "\n",
    "    jsonMetaDF = pd.read_json(\"metaDataJson.json\")\n",
    "\n",
    "    # TypeEnjoyer not provided (manual function) \n",
    "    if typeEnjoyer ==\"UserLikeImages\":\n",
    "        image = Image.open(\"images/\"+nomImage+'.jpg')\n",
    "        image.show()\n",
    "        while True:\n",
    "            a = input(\"Do you like that picture ? Please press 1 (YES) or 0 (NO)\")\n",
    "            if a in ('0','1'):\n",
    "                b = input(\"Please enter the most adequate tag (0 = default tag)\")\n",
    "                break\n",
    "             \n",
    "        return [int(a), b] \n",
    "    \n",
    "    # TypeEnjoyer provided (test function) \n",
    "    elif typeEnjoyer ==\"dogEnjoyer\":\n",
    "        return [int(\"Dog\" in jsonMetaDF[nomImage][\"tags\"]),'0']\n",
    "    elif typeEnjoyer =='fruitEnjoyer':\n",
    "        return [int(\"Fruit\" in jsonMetaDF[nomImage][\"tags\"]),'0']\n",
    "    elif typeEnjoyer =='lakeEnjoyer':\n",
    "        return [int(\"Lake\" in jsonMetaDF[nomImage][\"tags\"]),'0']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def cyclePropositionImage(numUser,typeEnjoyer=\"UserLikeImages\"):\n",
    "    # INPUT     : numUser (user ID as an integer ex:1)\n",
    "    #           : typeEnjoyer (OPTIONAL, it is a test parameter to tell the machine to like every image with a specific tag)\n",
    "    # DESCRIPTION : Predict which image the user will like, provide it to the use and fill in our user database that the user \n",
    "    # have now seen the image, and if he/she/{} liked it.\n",
    "\n",
    "    \n",
    "    \n",
    "    jsonMetaDF = pd.read_json(\"metaDataJson.json\")\n",
    "    jsonUserDF=pd.read_json(\"jsonUser.json\")\n",
    "\n",
    "    userId=\"user\"+str(numUser)\n",
    "    imageDonee=[]\n",
    "    imagePasDonnes=[]\n",
    "    imageAdonne=1\n",
    "\n",
    "    # extract the images, the user have not seen yet\n",
    "    jsonMetaKeys=jsonMetaDF.keys()\n",
    "    print(jsonMetaKeys)\n",
    "    random.shuffle(jsonMetaKeys.tolist())\n",
    "    for image in jsonMetaKeys:\n",
    "        if image not in jsonUserDF[userId][\"images\"]:\n",
    "            ana=analyseGlobal(numUser,image)\n",
    "            if ana==('Favorite'):\n",
    "                imageDonee.append(image)\n",
    "                break\n",
    "            else:\n",
    "                imagePasDonnes.append(image)\n",
    "\n",
    "    # show the user a random image which the model predict to be liked\n",
    "    if imageDonee!=[]:\n",
    "        imageAdonne=random.choice(imageDonee)\n",
    "        jsonUserDF[userId][\"images\"].append(imageAdonne)\n",
    "\n",
    "    # or another one if the images are all inadequaet\n",
    "    else:\n",
    "        imageAdonne=random.choice(imagePasDonnes)\n",
    "        jsonUserDF[userId][\"images\"].append(imageAdonne)\n",
    "    #print(imageAdonne)\n",
    "    res = demandeFavoriteOrNot(imageAdonne,typeEnjoyer)\n",
    "    if res[1] !='0' :\n",
    "        if res[1] in lstTag:\n",
    "            jsonMetaDF[imageAdonne][\"tags\"]=res[1]\n",
    "        else:\n",
    "            print( \"error : tag not in list, previous tag kept instead\")\n",
    "\n",
    "    jsonUserDF[userId][\"result\"].append(res[0])\n",
    "    \n",
    "    \n",
    "    jsonUserDF.to_json(\"jsonUser.json\",orient='columns',indent=4)               \n",
    "\n",
    "\n",
    "def testNcycle(N):\n",
    "    for i in range(N):\n",
    "        cyclePropositionImage(0)\n",
    "        cyclePropositionImage(1,\"dogEnjoyer\")\n",
    "        cyclePropositionImage(2,\"fruitEnjoyer\")\n",
    "        cyclePropositionImage(3,\"lakeEnjoyer\")\n",
    "testNcycle(7)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update user preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = \"user0\" #Select user\n",
    "\n",
    "def userPreferences(userName = None):\n",
    "\n",
    "     # INPUT     : userName (string)\n",
    "     # OUTPUT    : None\n",
    "     # DESCRIPTION : Sets the user preferences in jsonUser.json. Happens for all user if no argument is given\n",
    "     \n",
    "     # Get ima\n",
    "     jsonMetaDF = pd.read_json(\"metaDataJson.json\")\n",
    "\n",
    "     # Get user like\n",
    "     userDF = pd.read_json(\"jsonUser.json\")\n",
    "\n",
    "     # Sets the user list, for which the preferences will be updated\n",
    "     userlst = []\n",
    "     if userName == None:\n",
    "          for user in userDF:\n",
    "               userlst.append(user)\n",
    "     else:\n",
    "          userlst.append(user)\n",
    "\n",
    "     # Gets all images seen and liked by the user\n",
    "     for user in userlst:\n",
    "          userImages = userDF.loc[\"images\"][user]\n",
    "          userLike = userDF.loc[\"result\"][user]\n",
    "          likedImages = []\n",
    "          for item in userImages :\n",
    "               ind = userImages.index(item)\n",
    "               if userLike[ind] == 1:\n",
    "                    likedImages.append(item)\n",
    "\n",
    "          # Gets all liked images' data\n",
    "          if len(likedImages) > 0:\n",
    "               ori = []\n",
    "               siz = []\n",
    "               tagF = []\n",
    "               colorF = []\n",
    "               for image in likedImages :\n",
    "                    ori.append(jsonMetaDF.loc[\"orientation\"][image])\n",
    "                    siz.append(jsonMetaDF.loc[\"size\"][image])\n",
    "                    tagF.append(jsonMetaDF.loc[\"tags\"][image])\n",
    "                    colorF.append(jsonMetaDF.loc[\"dom\"][image])\n",
    "\n",
    "               # Gets the data most present in the user's liked images and sets them as his preferences\n",
    "               jsonUser=json.load(open(\"jsonUser.json\"))\n",
    "               jsonUser[user][\"orientation\"]=max(ori,key = ori.count)\n",
    "               jsonUser[user][\"size\"]=max(siz,key = siz.count)\n",
    "               jsonUser[user][\"tagFav\"]=max(tagF,key = tagF.count)\n",
    "               jsonUser[user][\"colorFav\"]=max(colorF,key = colorF.count)\n",
    "               \n",
    "               jsonUserStr = json.dumps(jsonUser, indent=4)\n",
    "               f = open(\"jsonUser.json\", \"w\")\n",
    "               f.write(jsonUserStr)\n",
    "               f.close()  \n",
    "\n",
    "userPreferences() # Updates all user preferences"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show User Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printUserPref(userName = None):\n",
    "    # INPUT     : userName (string)\n",
    "    # OUTPUT    : The user's preferences\n",
    "    # DESCRIPTION : Shows the selected user or all user's preferences is no argument is given\n",
    "\n",
    "    if userName == None:\n",
    "        userDF = pd.read_json(\"jsonUser.json\")\n",
    "    else :\n",
    "        userDF = pd.read_json(\"jsonUser.json\")\n",
    "        userDF = userDF[userName]\n",
    "    return userDF[\"orientation\":\"colorFav\"]\n",
    "\n",
    "printUserPref() # Show all user preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot user liked images' stats : tags, size, ...\n",
    "def plotPref(plotLst = [\"tags\",\"dom\",\"orientation\",\"size\"],userName = None):\n",
    "    # INPUT     : plotLst (lst), userName (string)\n",
    "    # OUTPUT    : None\n",
    "    # DESCRIPTION : Plots a specific user's like image data or plots all the data from the images in the databases.\n",
    "\n",
    "    userDF = pd.read_json(\"jsonUser.json\")\n",
    "    jsonMetaDF = pd.read_json(\"metaDataJson.json\")\n",
    "\n",
    "    toPlotCount = []\n",
    "    if type(plotLst) != list:\n",
    "        plotLst = [plotLst]\n",
    "    \n",
    "    if userName == None :\n",
    "        for stat in plotLst :\n",
    "            if stat in [\"tags\",\"dom\",\"orientation\",\"size\"]:     # Stats that can be plotted are in this list\n",
    "                toPlot = []\n",
    "                for image in jsonMetaDF :\n",
    "                    toPlot.append(jsonMetaDF.loc[stat][image])\n",
    "                    \n",
    "                toPlotCount.append(pd.Series(toPlot).value_counts())\n",
    "\n",
    "    if userName != None and userName in userDF:\n",
    "        for stat in plotLst :\n",
    "            if stat in [\"tags\",\"dom\",\"orientation\",\"size\"]:     # Stats that can be plotted are in this list\n",
    "                toPlot = []\n",
    "                for image in userDF[userName][\"images\"] :\n",
    "                    toPlot.append(jsonMetaDF.loc[stat][image])\n",
    "                toPlotCount.append(pd.Series(toPlot).value_counts())\n",
    "        \n",
    "    for plotCount in toPlotCount:\n",
    "        fig = plt.figure()\n",
    "        plotCount.plot.bar()\n",
    "    plt.show()\n",
    "\n",
    "plotPref([\"tags\",\"dom\",\"orientation\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "83f73d5875a575e504ba23451a5997fea59c0c75034f677431fe9f5bc2b0207e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
