{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation des fichiers utiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image, ExifTags\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "\n",
    "NOMBRE_IMAGE=141"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Demande de Json\n",
    "Nous Faisons une Requète WikiData pour demander un Json contenant le lien menant à des libres d'une certaine catégorie. Nous avons essayé plusieurs types d'images différentes :\n",
    "\n",
    "mythical creature = Q2239243<br>\n",
    "photograph = Q125191<br>\n",
    "flower = Q506<br>\n",
    "fruit = Q1364<br>\n",
    "Chien = Q144<br>\n",
    "lac  = Q23397<br>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SELECT ?image ?im WHERE {\n",
    "  ?image wdt:P31 wd:Q506.\n",
    "  ?image wdt:P18 ?im\n",
    "  }\n",
    "LIMIT 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstSources = {\"Fruit\":1364,\"Dog\":144,\"Lake\":23397}\n",
    "limitPerSources = 5\n",
    "sources = {}\n",
    "tagTemp = []\n",
    "for key,value in lstSources.items():    #Get all images to download\n",
    "    url =\"https://query.wikidata.org/sparql?query=SELECT%20%3Fimage%20%3Fim%20WHERE%20%7B%0A%20%20%3Fimage%20wdt%3AP31%20wd%3AQ\"+str(value)+\".%0A%20%20%3Fimage%20wdt%3AP18%20%3Fim%0A%20%20%7D%0ALIMIT%20\"+str(limitPerSources)+\"&format=json\"\n",
    "    response = urllib.request.urlopen(url)\n",
    "    myJson = json.loads(response.read().decode(\"utf-8\"))\n",
    "    \n",
    "    for image in myJson[\"results\"][\"bindings\"]:  #Add the tag to the image\n",
    "        image['tag'] = key\n",
    "        \n",
    "    if sources == {}:   #Make one big json containing all images\n",
    "        sources = myJson\n",
    "    else:\n",
    "        sources[\"results\"][\"bindings\"] = sources[\"results\"][\"bindings\"]+myJson[\"results\"][\"bindings\"]\n",
    "\n",
    "myJsonNormalized = pd.json_normalize(sources)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Télechargement des images ##\n",
    "A partir du Json contenant les liens menant aux images, nous lancons des requètes URLLIB pour télecharger ces images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "#telechargement des images\n",
    "\n",
    "responseJson = myJsonNormalized[\"results.bindings\"]\n",
    "index=0\n",
    "lstTag=[]\n",
    "for i in range(len(responseJson[0])):   \n",
    "    imageLink = responseJson[0][i][\"im\"][\"value\"]\n",
    "    lstTag.append(responseJson[0][i][\"tag\"])\n",
    "    print(index)\n",
    "    \n",
    "    im = \"./images/image\"+str(index)+\".jpg\"\n",
    "    urllib.request.urlretrieve(imageLink, im)\n",
    "    index +=1\n",
    "\n",
    "    try:\n",
    "        imgfile = Image.open(im).convert(\"RGB\")\n",
    "    except:\n",
    "        index-=1\n",
    "        del lstTag[-1]\n",
    "        print(\"pas fonctionne\")\n",
    "    \n",
    "NOMBRE_IMAGE=index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Récupération des métadonnées\n",
    "L'obhectif de cette partie est de récupérer les informations des images, nous récupérons les images suivantes :<br>\n",
    "1. Récupération Exif utiles\n",
    "2. Récupération couleurs dominantes (K-means)\n",
    "3. Récupération taille des images\n",
    "4. Détermination portrait ou paysage\n",
    "\n",
    "Apres cela, nous avons creer un Json **metaDataJson.json** contenant toutes les informationns precedentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération des métadonnées\n",
    "\n",
    "metaData ={}\n",
    "for i in range(NOMBRE_IMAGE):\n",
    "    im = \"./images/image\"+str(i)+\".jpg\"\n",
    "    try:\n",
    "        imgfile = Image.open(im).convert(\"RGB\")\n",
    "\n",
    "        #Recupération Exif utiles\n",
    "        exif = {}\n",
    "        exifCritere= (\"Model\",\"Make\",\"ImageDescription\",\"ExposureTime\",\"GPSInfo\",\"ISO\",\"DateTimeOriginal\")\n",
    "        for k,v in  imgfile.getexif().items() :\n",
    "            if k in ExifTags.TAGS :\n",
    "                if ExifTags.TAGS[k] in exifCritere:\n",
    "                    exif = {ExifTags.TAGS[k]:v}\n",
    "\n",
    "        # Recupération couleurs dominantes (K-means)\n",
    "        numarray = np.array(imgfile.getdata(), np.uint8)\n",
    "        clusters  = MiniBatchKMeans(n_clusters=3, n_init=2) \n",
    "        clusters.fit(numarray)\n",
    "        L = clusters.cluster_centers_.astype(int).tolist()\n",
    "        if L[0][0]>L[0][1] and L[0][0]>L[0][2]:\n",
    "            domColor = \"Red\"\n",
    "        elif L[0][1]>L[0][0] and L[0][1]>L[0][2]:\n",
    "            domColor = \"Green\"\n",
    "        elif L[0][2]>L[0][0] and L[0][2]>L[0][1]:\n",
    "            domColor = \"Blue\"\n",
    "        elif L[0][0]==L[0][1]==L[0][2]:\n",
    "            domColor = \"White\"\n",
    "        else:\n",
    "            domColor = \"None\"\n",
    "\n",
    "        # Recupération taille des images\n",
    "        width = imgfile.width\n",
    "        height = imgfile.height\n",
    "        mode = imgfile.mode\n",
    "\n",
    "        # Détermination portrait ou paysage\n",
    "        if abs(1-width/height)<0.1 :\n",
    "            orientation='carre' \n",
    "        elif width>height:\n",
    "            orientation='paysage'\n",
    "        else: \n",
    "            orientation=\"portrait\"\n",
    "\n",
    "        # Get image size (big, small, ...)\n",
    "        pixelCount = width * height\n",
    " \n",
    "        if pixelCount >= 1920*1080:\n",
    "            size = \"Grande\"\n",
    "        elif pixelCount >= 1280*720:\n",
    "            size = \"Moyenne\"\n",
    "        elif pixelCount >= 720*480:\n",
    "            size = \"Petite\"\n",
    "        elif pixelCount < 720*480:\n",
    "            size = \"Vignette\"\n",
    "        else:\n",
    "            size = \"WTF\"\n",
    "\n",
    "        metaData[\"image\"+str(i)] = { \"width\" : width, \"height\": height, \"exif\": exif, \"mode\":mode, \"tags\":[lstTag[i]], \"couleurs\":L, \"orientation\":orientation, \"size\":size, \"dom\":domColor}\n",
    "    except Exception:\n",
    "        print(\"l'image \"+str(i) +\" ne peut pas etre ouverte\")\n",
    "metaData\n",
    "\n",
    "metaDatajson = json.dumps(metaData)\n",
    "f = open(\"metaDataJson.json\", \"w\")\n",
    "f.write(metaDatajson)\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[[158 142   9 209 204  19  71  68  31]\n",
      " [104  98  72 212 175 177 236  41  59]\n",
      " [ 41  41  41 247 247 247 151 151 151]\n",
      " [173  65  38 213 153  68  77  44  35]]\n",
      "[1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "def analyseCouleur(numUser): \n",
    "    jsonUser=json.load(open(\"jsonUser.json\"))[numUser]\n",
    "    jsonMeta=json.load(open(\"metaDatajson.json\"))\n",
    "    couleurs=[]\n",
    "\n",
    "    for image in jsonMeta:\n",
    "        if image in jsonUser[\"data\"][\"image\"]:\n",
    "            couleurs.append(flatten(jsonMeta[image][\"couleurs\"]))\n",
    "            print(1)\n",
    "            \n",
    "    numarray=np.array(couleurs)\n",
    "    like=np.array(jsonUser[\"data\"][\"resultat\"])\n",
    "    \n",
    "    print(numarray)\n",
    "    #modele des couleurs\n",
    "    percep = Perceptron(max_iter=1000)\n",
    "    percep.fit(numarray, like)\n",
    "    \n",
    "    x_predict = np.array([[\n",
    "        139,\n",
    "        150,\n",
    "        102,\n",
    "        251,\n",
    "        251,\n",
    "        249,\n",
    "        57,\n",
    "        83,\n",
    "        25\n",
    "    ]])\n",
    "    # x_predict =[]\n",
    "    # for image in jsonMeta:\n",
    "    #     x_predict.append(flatten(jsonMeta[image][\"couleurs\"]))\n",
    "    # print(x_predict)\n",
    "    y_predict = percep.predict(x_predict)\n",
    "    return y_predict[0]\n",
    "analyseCouleur(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createUser(nom, prenom, images,like):\n",
    "    jsonUser=json.load(open(\"jsonUser.json\"))\n",
    "    doc={\"nom\": nom,\"prenom\" :prenom, \"data\" : {\"like\":[],\"annee\":\"\",\"format\":\"\",\"taille\":\"\",\"tagFav\":\"\",\"model\":\"\",\"couleursFav\":\"\"}}\n",
    "    jsonUser.append(doc)\n",
    "    jsonUserStr = json.dumps(jsonUser, indent=4)\n",
    "    f = open(\"jsonUser.json\", \"w\")\n",
    "    f.write(jsonUserStr)\n",
    "    f.close()  \n",
    "#createUser(\"myName\", \"effef\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NotFavorite']\n",
      "[0.67520216 0.20215633 0.12264151 0.        ]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Get image data\n",
    "jsonMetaDF = pd.read_json(\"metaDataJson.json\")\n",
    "lstTags = jsonMetaDF.loc[\"tags\"].to_list()\n",
    "lstOrientation = jsonMetaDF.loc[\"orientation\"].to_list()\n",
    "\n",
    "data = []\n",
    "for item in jsonMetaDF:\n",
    "    imageDesc = []\n",
    "    imageDesc.append(jsonMetaDF.loc[\"dom\"][item])\n",
    "    imageDesc.append(jsonMetaDF.loc[\"tags\"][item][0])\n",
    "    imageDesc.append(jsonMetaDF.loc[\"size\"][item])\n",
    "    imageDesc.append(jsonMetaDF.loc[\"orientation\"][item])\n",
    "    data.append(imageDesc)\n",
    "\n",
    "# Get user like\n",
    "userDF = pd.read_json(\"jsonUser.json\")\n",
    "userIndex = 0 # Get user0\n",
    "userLike = userDF.loc[\"data\"][userIndex][\"like\"]\n",
    "userLikeLst = []\n",
    "\n",
    "result = []\n",
    "for item in jsonMetaDF:\n",
    "    if item in userLike:\n",
    "        result.append(\"Favorite\")\n",
    "    else :\n",
    "        result.append(\"NotFavorite\")\n",
    "\n",
    "\n",
    "# creating dataframes\n",
    "dataframe = pd.DataFrame(data, columns=[\"dom\", \"tags\", \"size\", \"orientation\"])\n",
    "resultframe = pd.DataFrame(result, columns=[\"favorite\"])\n",
    "\n",
    "# generating numerical labels\n",
    "le1 = LabelEncoder()\n",
    "dataframe[\"dom\"] = le1.fit_transform(dataframe[\"dom\"])\n",
    "\n",
    "le2 = LabelEncoder()\n",
    "dataframe[\"tags\"] = le2.fit_transform(dataframe[\"tags\"])\n",
    "\n",
    "le3 = LabelEncoder()\n",
    "dataframe[\"size\"] = le3.fit_transform(dataframe[\"size\"])\n",
    "\n",
    "le4 = LabelEncoder()\n",
    "dataframe[\"orientation\"] = le4.fit_transform(dataframe[\"orientation\"])\n",
    "\n",
    "le5 = LabelEncoder()\n",
    "resultframe[\"favorite\"] = le5.fit_transform(resultframe[\"favorite\"])\n",
    "\n",
    "# Use of decision tree classifiers\n",
    "dtc = tree.DecisionTreeClassifier()\n",
    "dtc = dtc.fit(dataframe.values, resultframe)\n",
    "\n",
    "# prediction\n",
    "prediction = dtc.predict(\n",
    "    [\n",
    "        [\n",
    "            le1.transform([\"Blue\"])[0],\n",
    "            le2.transform([\"Dog\"])[0],\n",
    "            le3.transform([\"Grande\"])[0],\n",
    "            le4.transform([\"portrait\"])[0],\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "print(le5.inverse_transform(prediction))\n",
    "print(dtc.feature_importances_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brouillon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse(numUser): \n",
    "jsonUser=json.load(open(\"jsonUser.json\"))[numUser]\n",
    "jsonMeta=json.load(open(\"metaDatajson.json\"))\n",
    "couleurs=[]\n",
    "dataArray=[]\n",
    "for image in jsonMeta:\n",
    "    if image in jsonUser[\"data\"][\"image\"]:\n",
    "    #image correspond maintenant aux informations des images testees\n",
    "        L=[]\n",
    "        dataImage=[]\n",
    "        if jsonMeta[image][\"tags\"]==[]:\n",
    "            dataImage.append(None)\n",
    "        else:\n",
    "            dataImage.append(jsonMeta[image][\"tags\"])\n",
    "        dataImage.append(jsonMeta[image][\"orientation\"])\n",
    "        dataImage.append(jsonMeta[image][\"width\"])\n",
    "\n",
    "        for couleur in jsonMeta[image][\"couleurs\"]:\n",
    "            for valeurRBG in couleur:\n",
    "                L.append(valeurRBG)\n",
    "        dataArray.append(dataImage)\n",
    "        couleurs.append(L)\n",
    "print(dataArray)\n",
    "numarray=np.array(couleurs)\n",
    "like=np.array(jsonUser[\"data\"][\"resultat\"])\n",
    "    \n",
    "#modele des couleurs\n",
    "percep = Perceptron(max_iter=1000)\n",
    "percep.fit(numarray, like)\n",
    "    \n",
    "\n",
    "#modele arbre de decision generale\n",
    "dataFrame = pd.DataFrame(dataArray, columns=[\"tags\", \"orientation\", \"mode\"])\n",
    "likeFrame=pd.DataFrame(like,columns=['like'])\n",
    "\n",
    "\n",
    "le1 = LabelEncoder()\n",
    "dataFrame['tags'] = le1.fit_transform(dataFrame['tags'])\n",
    "\n",
    "le2 = LabelEncoder()\n",
    "dataFrame['orientation'] = le2.fit_transform(dataFrame['orientation'])\n",
    "\n",
    "le3 = LabelEncoder()\n",
    "dataFrame['mode'] = le3.fit_transform(dataFrame['mode'])\n",
    "\n",
    "le4 = LabelEncoder()\n",
    "likeFrame['like'] = le4.fit_transform(likeFrame['like'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "83f73d5875a575e504ba23451a5997fea59c0c75034f677431fe9f5bc2b0207e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
