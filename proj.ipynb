{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation of libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image, ExifTags\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import Perceptron\n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Getting a Json with Wikidata Query\n",
    "We created a WikiData Query to request a Json file, containing the links to open-licensed images. We used images with different themes:<br>\n",
    "\n",
    "fruit = Q1364<br>\n",
    "Dog = Q144<br>\n",
    "lake  = Q23397<br>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SELECT ?image ?im WHERE {\n",
    "  ?image wdt:P31 wd:Q506.\n",
    "  ?image wdt:P18 ?im\n",
    "  }\n",
    "LIMIT 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'head': {'vars': ['image', 'im']}, 'results': {'bindings': [{'image': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q337'}, 'im': {'type': 'uri', 'value': 'http://commons.wikimedia.org/wiki/Special:FilePath/Lake%20Chaubunagungamaugg.jpg'}, 'tag': 'Lake'}, {'image': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q1062'}, 'im': {'type': 'uri', 'value': 'http://commons.wikimedia.org/wiki/Special:FilePath/ISS-36%20Lake%20Ontario%20%28horizontal%29.jpg'}, 'tag': 'Lake'}, {'image': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q1066'}, 'im': {'type': 'uri', 'value': 'http://commons.wikimedia.org/wiki/Special:FilePath/Lake%20Superior%2C%20ISS.jpg'}, 'tag': 'Lake'}, {'image': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q1169'}, 'im': {'type': 'uri', 'value': 'http://commons.wikimedia.org/wiki/Special:FilePath/Lake%20Michigan%20in%20true%20color.jpg'}, 'tag': 'Lake'}, {'image': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q1383'}, 'im': {'type': 'uri', 'value': 'http://commons.wikimedia.org/wiki/Special:FilePath/Lake%20Huron%20in%20winter.jpg'}, 'tag': 'Lake'}]}}\n"
     ]
    }
   ],
   "source": [
    "lstSources = {\"Fruit\":1364,\"Dog\":144,\"Lake\":23397} #Sources from which we download the images\n",
    "limitPerSources = 5\n",
    "sources = {}\n",
    "tagTemp = []\n",
    "for key,value in lstSources.items():    #Get all images to download\n",
    "    url =\"https://query.wikidata.org/sparql?query=SELECT%20%3Fimage%20%3Fim%20WHERE%20%7B%0A%20%20%3Fimage%20wdt%3AP31%20wd%3AQ\"+str(value)+\".%0A%20%20%3Fimage%20wdt%3AP18%20%3Fim%0A%20%20%7D%0ALIMIT%20\"+str(limitPerSources)+\"&format=json\"\n",
    "    response = urllib.request.urlopen(url)\n",
    "    myJson = json.loads(response.read().decode(\"utf-8\"))\n",
    "    \n",
    "    for image in myJson[\"results\"][\"bindings\"]:  #Add the tag to the image\n",
    "        image['tag'] = key\n",
    "        \n",
    "    if sources == {}:   #Make one big json containing all images information\n",
    "        sources = myJson\n",
    "    else:\n",
    "        sources[\"results\"][\"bindings\"] = sources[\"results\"][\"bindings\"]+myJson[\"results\"][\"bindings\"]\n",
    "\n",
    "myJsonNormalized = pd.json_normalize(sources)\n",
    "print(myJson)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Télechargement des images ##\n",
    "A partir du Json contenant les liens menant aux images, nous lancons des requètes URLLIB pour télecharger ces images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading images\n",
    "\n",
    "responseJson = myJsonNormalized[\"results.bindings\"]\n",
    "index=0\n",
    "lstTag=[]\n",
    "for i in range(len(responseJson[0])):   \n",
    "    # Getting image Link for each image\n",
    "    imageLink = responseJson[0][i][\"im\"][\"value\"]\n",
    "    lstTag.append(responseJson[0][i][\"tag\"])\n",
    "    \n",
    "    # Requesting to Download images and saving it as \"images$.jpg\" where $ is the image id\n",
    "    im = \"./images/image\"+str(index)+\".jpg\"\n",
    "    urllib.request.urlretrieve(imageLink, im)\n",
    "    index +=1\n",
    "\n",
    "    #Convert images to RGB, to prevent future errors\n",
    "    try:\n",
    "        imgfile = Image.open(im).convert(\"RGB\")\n",
    "    except:\n",
    "        index-=1\n",
    "        del lstTag[-1]\n",
    "        print(\"pas fonctionne\")\n",
    "    \n",
    "NOMBRE_IMAGE=index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Récupération des métadonnées\n",
    "L'obhectif de cette partie est de récupérer les informations des images, nous récupérons les images suivantes :<br>\n",
    "1. Récupération Exif utiles\n",
    "2. Récupération couleurs dominantes (K-means)\n",
    "3. Récupération taille des images\n",
    "4. Détermination portrait ou paysage\n",
    "\n",
    "Apres cela, nous avons creer un Json **metaDataJson.json** contenant toutes les informationns precedentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting meta-data\n",
    "\n",
    "metaData ={}\n",
    "for i in range(NOMBRE_IMAGE):\n",
    "    im = \"./images/image\"+str(i)+\".jpg\"\n",
    "    try:\n",
    "        imgfile = Image.open(im).convert(\"RGB\")\n",
    "\n",
    "        # selecting the useful Exif\n",
    "        exif = {}\n",
    "        exifCritere= (\"Model\",\"Make\",\"ImageDescription\",\"ExposureTime\",\"GPSInfo\",\"ISO\",\"DateTimeOriginal\")\n",
    "        for k,v in  imgfile.getexif().items() :\n",
    "            if k in ExifTags.TAGS :\n",
    "                if ExifTags.TAGS[k] in exifCritere:\n",
    "                    exif = {ExifTags.TAGS[k]:v}\n",
    "\n",
    "        # Collecting 3 predominant colors (using K-means)\n",
    "        numarray = np.array(imgfile.getdata(), np.uint8)\n",
    "        clusters  = MiniBatchKMeans(n_clusters=3, n_init=2) \n",
    "        clusters.fit(numarray)\n",
    "        L = clusters.cluster_centers_.astype(int).tolist()\n",
    "\n",
    "        # Really simply setting the dominant color using the value of the most present color in the image\n",
    "        if L[0][0]>L[0][1] and L[0][0]>L[0][2]:\n",
    "            domColor = \"Red\"\n",
    "        elif L[0][1]>L[0][0] and L[0][1]>L[0][2]:\n",
    "            domColor = \"Green\"\n",
    "        elif L[0][2]>L[0][0] and L[0][2]>L[0][1]:\n",
    "            domColor = \"Blue\"\n",
    "        elif L[0][0]==L[0][1]==L[0][2]:\n",
    "            domColor = \"White\"\n",
    "        else:\n",
    "            domColor = \"None\"\n",
    "\n",
    "        # Collecting images sizez\n",
    "        width = imgfile.width\n",
    "        height = imgfile.height\n",
    "        mode = imgfile.mode\n",
    "\n",
    "        # identify image orientation\n",
    "        if abs(1-width/height)<0.1 :\n",
    "            orientation='carre' \n",
    "        elif width>height:\n",
    "            orientation='paysage'\n",
    "        else: \n",
    "            orientation=\"portrait\"\n",
    "\n",
    "        # Get image size (big, small, ...)\n",
    "        pixelCount = width * height\n",
    "\n",
    "        if pixelCount >= 1920*1080:\n",
    "            size = \"Grande\"\n",
    "        elif pixelCount >= 1280*720:\n",
    "            size = \"Moyenne\"\n",
    "        elif pixelCount >= 720*480:\n",
    "            size = \"Petite\"\n",
    "        elif pixelCount < 720*480:\n",
    "            size = \"Vignette\"\n",
    "        else:\n",
    "            size = \"WTF\"\n",
    "\n",
    "        metaData[\"image\"+str(i)] = { \"width\" : width, \"height\": height, \"exif\": exif, \"mode\":mode, \"tags\":[lstTag[i]], \"couleurs\":L, \"orientation\":orientation, \"size\":size, \"dom\":domColor}\n",
    "    except Exception:\n",
    "        print(\"l'image \"+str(i) +\" ne peut pas etre ouverte\")\n",
    "metaData\n",
    "\n",
    "metaDatajson = json.dumps(metaData)\n",
    "f = open(\"metaDataJson.json\", \"w\")\n",
    "f.write(metaDatajson)\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis\n",
    "Consist of 2 parts :\n",
    "1. The first one  color analysis to get if an image has a colors patern close to mages previously liked image by the user. Then we feed it to a more global analysis.\n",
    "2. The global analysis, use a decision tree classifier to analyse the data in our user database, and the result of our color analyses, and predict if an image is likely to be liked by the user.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(L):\n",
    "# INPUT     : L (List)\n",
    "# OUTPUT    : Flattened version of L\n",
    "# DESCRIPTION : return a flattened version of the input list \"L\" : [[1,2,3],[1,2]] -> [1,2,3,1,2]\n",
    "    return [item for sublist in L for item in sublist]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def analyseCouleur(nameUser,nomImage): \n",
    "# INPUT     : numUser (user ID as an integer ex:1)\n",
    "#           : nomImage (the name in metadatajson.json of the image to predictas a string ex:\"image0\")\n",
    "# OUTPUT    : y_predict[0] (an integer either 0 if the algorithm precict the user won't like the image\n",
    "#             or 1 if the image is predicted to be liked)\n",
    "# DESCRIPTION : predict if an user will liked an image, based solely on the image color mathing previous images\n",
    "\n",
    "\n",
    "    couleurs = []\n",
    "    jsonUserDF=pd.read_json(\"jsonUser.json\")\n",
    "    jsonMetaDF=pd.read_json(\"metaDataJson.json\")\n",
    "    #userId=\"user\"+str(numUser)\n",
    "\n",
    "    for image in jsonUserDF[nameUser][\"images\"]:\n",
    "        couleurs.append(flatten(jsonMetaDF[image][\"couleurs\"]))\n",
    "        \n",
    "    # creating training the model with what the user have already seen\n",
    "    numarray=np.array(couleurs)\n",
    "    like=np.array(jsonUserDF[nameUser][\"result\"])\n",
    "  \n",
    "    percep = Perceptron(max_iter=1000)\n",
    "    percep.fit(numarray, like)\n",
    "\n",
    "\n",
    "    # predicting if the use would like the input image\n",
    "    x_predict = np.array([flatten(jsonMetaDF[nomImage][\"couleurs\"])])\n",
    "    y_predict = percep.predict(x_predict)\n",
    "\n",
    "    return y_predict[0]\n",
    "\n",
    "# exemple to test the function by itself:\n",
    "# analyseCouleur(\"user1\",\"image1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\augus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but OrdinalEncoder was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\augus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but OrdinalEncoder was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\augus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but OrdinalEncoder was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\augus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but OrdinalEncoder was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\augus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but OrdinalEncoder was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Favorite'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def analyseGlobal(nameUser,nomImage):\n",
    "    # INPUT     : nameUser (string), nomImage (string)\n",
    "    # OUTPUT    : prediction\n",
    "    # DESCRIPTION : returns whether the user should or shouldn't like the image (\"Favorite\" or \"NotFavorite\")\n",
    "\n",
    "    # Get image data\n",
    "    jsonMetaDF = pd.read_json(\"metaDataJson.json\")\n",
    "\n",
    "    # Get user like\n",
    "    userDF = pd.read_json(\"jsonUser.json\")\n",
    "    userImages = userDF.loc[\"images\"][nameUser]\n",
    "    userLike = userDF.loc[\"result\"][nameUser]\n",
    "\n",
    "    # Get data from the images already seen by the user for the training\n",
    "    data = []\n",
    "    for item in userImages:\n",
    "        imageDesc = []\n",
    "        imageDesc.append(jsonMetaDF.loc[\"dom\"][item])\n",
    "        imageDesc.append(jsonMetaDF.loc[\"tags\"][item][0])\n",
    "        imageDesc.append(jsonMetaDF.loc[\"size\"][item])\n",
    "        imageDesc.append(jsonMetaDF.loc[\"orientation\"][item])\n",
    "        imageDesc.append(analyseCouleur(nameUser,item))\n",
    "        data.append(imageDesc)\n",
    "\n",
    "    # Get whether the user liked or not the images for the training\n",
    "    result = [None]*len(userImages)\n",
    "    for item in jsonMetaDF:\n",
    "        if item in userImages:\n",
    "            ind = userImages.index(item)\n",
    "            if userLike[ind] == 1:\n",
    "                result[ind]=\"Favorite\"\n",
    "            else :\n",
    "                result[ind]=\"NotFavorite\"\n",
    "\n",
    "    # creating dataframes\n",
    "    dataframe = pd.DataFrame(data, columns=[\"dom\", \"tags\", \"size\", \"orientation\",\"likedColor\"])\n",
    "    resultframe = pd.DataFrame(result, columns=[\"favorite\"])\n",
    "\n",
    "    le1 = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "    dataframe[\"dom\"] = le1.fit_transform(dataframe[\"dom\"].values.reshape(-1,1))\n",
    "\n",
    "    le2 = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "    dataframe[\"tags\"] = le2.fit_transform(dataframe[\"tags\"].values.reshape(-1,1))\n",
    "\n",
    "    le3 = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "    dataframe[\"size\"] = le3.fit_transform(dataframe[\"size\"].values.reshape(-1,1))\n",
    "\n",
    "    le4 = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "    dataframe[\"orientation\"] = le4.fit_transform(dataframe[\"orientation\"].values.reshape(-1,1))\n",
    "\n",
    "    le5 = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "    dataframe[\"likedColor\"] = le5.fit_transform(dataframe[\"likedColor\"].values.reshape(-1,1))\n",
    "\n",
    "    le6 = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "    resultframe[\"favorite\"] = le6.fit_transform(resultframe[\"favorite\"].values.reshape(-1,1))\n",
    "    \n",
    "    # Use of decision tree classifiers\n",
    "    dtc = tree.DecisionTreeClassifier()\n",
    "    dtc = dtc.fit(dataframe.values, resultframe)\n",
    "\n",
    "\n",
    "    #prediction\n",
    "\n",
    "    # Get data from the image we want to predict\n",
    "    colorP = jsonMetaDF.loc[\"dom\"][nomImage]\n",
    "    tagsP = jsonMetaDF.loc[\"tags\"][nomImage]\n",
    "    sizeP = jsonMetaDF.loc[\"size\"][nomImage]\n",
    "    orientationP = jsonMetaDF.loc[\"orientation\"][nomImage]\n",
    "    colorLikeP = analyseCouleur(nameUser,nomImage)\n",
    "    \n",
    "    prediction = dtc.predict(np.array([\n",
    "        \n",
    "            le1.transform(pd.DataFrame([colorP], columns=[\"couleur\"]))[0],\n",
    "            le2.transform(pd.DataFrame([tagsP], columns=[\"tag\"]))[0],\n",
    "            le3.transform(pd.DataFrame([sizeP], columns=[\"size\"]))[0],\n",
    "            le4.transform(pd.DataFrame([orientationP], columns=[\"orientation\"]))[0],\n",
    "            le5.transform(pd.DataFrame([colorLikeP], columns=[\"likedColor\"]))[0],\n",
    "        \n",
    "    ]).reshape(1,-1))\n",
    "    \n",
    "    print(dtc.feature_importances_)\n",
    "    return le6.inverse_transform(prediction.reshape(-1,1)).tolist()[0][0]\n",
    "    \n",
    "#TODO Vérifier que likedColor pas toujours le seul critère déterminant\n",
    "analyseGlobal(\"user4\",\"image8\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Systeme de recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createUser(nom, prenom, images = None,like = None):\n",
    "# INPUT     : nom (User first name as a string)\n",
    "#           : prenom (User last name as a string)\n",
    "#           : images (OPTIONAL, a list of all images the user have already seen, ex:[image1,image2])\n",
    "#           : prenom (OPTIONAL, a list of 0 and 1, which corresponds to images, ex:[0,1] meaning the user only like the second image)\n",
    "# DESCRIPTION : Dcreate a new user in our user database (jsonUser.json), using name, last name, and already seen images as input\n",
    "\n",
    "\n",
    "    jsonUser=json.load(open(\"jsonUser.json\"))\n",
    "    userId=\"user\"+str(len(jsonUser))\n",
    "\n",
    "    # If optional arguments,like and images are not presented, set them at random\n",
    "    if images == None:\n",
    "        firstImage = \"image\" + str(random.randint(0,NOMBRE_IMAGE-1))\n",
    "        images = [firstImage]\n",
    "        like = [random.randint(0,1)]\n",
    "    \n",
    "    # Creating the json structure\n",
    "    if len(images) == len(like) :\n",
    "        jsonUser[userId]={\"nom\" : nom,\"prenom\" : prenom, \"images\":images,\"result\":like,\"year\":\"\",\"size\":\"\",\"tagFav\":\"\",\"orientation\":\"\",\"couleursFav\":\"\"}\n",
    "    else :\n",
    "        print(\"Please give image and like list of same size\")\n",
    "    \n",
    "    # Storing the structure in our database (jsonUser.json)\n",
    "    jsonUserStr = json.dumps(jsonUser, indent=4)\n",
    "    f = open(\"jsonUser.json\", \"w\")\n",
    "    f.write(jsonUserStr)\n",
    "    f.close()  \n",
    "createUser(\"Jean\", \"Paul\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\augus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\augus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\augus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 79\u001b[0m\n\u001b[0;32m     77\u001b[0m         cyclePropositionImage(\u001b[39m2\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mfruitEnjoyer\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     78\u001b[0m         cyclePropositionImage(\u001b[39m3\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mlakeEnjoyer\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 79\u001b[0m testNcycle(\u001b[39m9\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[9], line 75\u001b[0m, in \u001b[0;36mtestNcycle\u001b[1;34m(N)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtestNcycle\u001b[39m(N):\n\u001b[0;32m     74\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(N):\n\u001b[1;32m---> 75\u001b[0m         cyclePropositionImage(\u001b[39m0\u001b[39;49m)\n\u001b[0;32m     76\u001b[0m         cyclePropositionImage(\u001b[39m1\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mdogEnjoyer\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     77\u001b[0m         cyclePropositionImage(\u001b[39m2\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mfruitEnjoyer\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[9], line 51\u001b[0m, in \u001b[0;36mcyclePropositionImage\u001b[1;34m(numUser, typeEnjoyer)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[39mfor\u001b[39;00m image \u001b[39min\u001b[39;00m jsonMetaDF:\n\u001b[0;32m     49\u001b[0m     \u001b[39mif\u001b[39;00m image \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m jsonUserDF[userId][\u001b[39m\"\u001b[39m\u001b[39mimages\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m---> 51\u001b[0m         ana\u001b[39m=\u001b[39manalyseGlobal(numUser,image)\n\u001b[0;32m     52\u001b[0m         \u001b[39mif\u001b[39;00m ana\u001b[39m==\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mFavorite\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     53\u001b[0m             imageDonee\u001b[39m.\u001b[39mappend(image)\n",
      "Cell \u001b[1;32mIn[7], line 22\u001b[0m, in \u001b[0;36manalyseGlobal\u001b[1;34m(nameUser, nomImage)\u001b[0m\n\u001b[0;32m     20\u001b[0m     imageDesc\u001b[39m.\u001b[39mappend(jsonMetaDF\u001b[39m.\u001b[39mloc[\u001b[39m\"\u001b[39m\u001b[39msize\u001b[39m\u001b[39m\"\u001b[39m][item])\n\u001b[0;32m     21\u001b[0m     imageDesc\u001b[39m.\u001b[39mappend(jsonMetaDF\u001b[39m.\u001b[39mloc[\u001b[39m\"\u001b[39m\u001b[39morientation\u001b[39m\u001b[39m\"\u001b[39m][item])\n\u001b[1;32m---> 22\u001b[0m     imageDesc\u001b[39m.\u001b[39mappend(analyseCouleur(nameUser,item))\n\u001b[0;32m     23\u001b[0m     data\u001b[39m.\u001b[39mappend(imageDesc)\n\u001b[0;32m     25\u001b[0m \u001b[39m# Get whether the user liked or not the images for the training\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 23\u001b[0m, in \u001b[0;36manalyseCouleur\u001b[1;34m(nameUser, nomImage)\u001b[0m\n\u001b[0;32m     20\u001b[0m jsonMetaDF\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mread_json(\u001b[39m\"\u001b[39m\u001b[39mmetaDataJson.json\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[39m#userId=\"user\"+str(numUser)\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[39mfor\u001b[39;00m image \u001b[39min\u001b[39;00m jsonUserDF[nameUser][\u001b[39m\"\u001b[39m\u001b[39mimages\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m     24\u001b[0m     couleurs\u001b[39m.\u001b[39mappend(flatten(jsonMetaDF[image][\u001b[39m\"\u001b[39m\u001b[39mcouleurs\u001b[39m\u001b[39m\"\u001b[39m]))\n\u001b[0;32m     26\u001b[0m \u001b[39m# creating training the model with what the user have already seen\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\augus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\augus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "def demandeFavoriteOrNot(nomImage,typeEnjoyer=\"UserLikeImages\"):\n",
    "# INPUT     : nomImage (the name in metadatajson.json of the image to predictas a string ex:\"image0\")\n",
    "#           : typeEnjoyer (OPTIONAL, it is a test parameter to tell the machine to like every image with a specific tag)\n",
    "# OUTPUT    : 0(int) or 1(int) (0 means the user disliked the image, 1 the user liked)\n",
    "# DESCRIPTION : Provide the image to the user and asked if the user like it. If thhe Optional argument typeEnjoyer\n",
    "#             : is provided, it automatically fill the likes depending of the parameter value.\n",
    "\n",
    "\n",
    "    jsonMetaDF = pd.read_json(\"metaDataJson.json\")\n",
    "\n",
    "    # TypeEnjoyer not provided (manual function) \n",
    "    if typeEnjoyer ==\"UserLikeImages\":\n",
    "        image = Image.open(\"images/\"+nomImage+'.jpg')\n",
    "        image.show()\n",
    "        while True:\n",
    "            a = input(\"Do you like that picture ? Please press 1 (YES) or 0 (NO)\")\n",
    "            if a in ('0','1'):\n",
    "                break\n",
    "        return int(a) \n",
    "    \n",
    "    # TypeEnjoyer provided (test function) \n",
    "    elif typeEnjoyer ==\"dogEnjoyer\":\n",
    "        return int(\"Dog\" in jsonMetaDF[nomImage][\"tags\"])\n",
    "    elif typeEnjoyer =='fruitEnjoyer':\n",
    "        return int(\"Fruit\" in jsonMetaDF[nomImage][\"tags\"])\n",
    "    elif typeEnjoyer =='lakeEnjoyer':\n",
    "        return int(\"Lake\" in jsonMetaDF[nomImage][\"tags\"])\n",
    "           \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def cyclePropositionImage(numUser,typeEnjoyer=\"UserLikeImages\"):\n",
    "    # INPUT     : numUser (user ID as an integer ex:1)\n",
    "    #           : typeEnjoyer (OPTIONAL, it is a test parameter to tell the machine to like every image with a specific tag)\n",
    "    # DESCRIPTION : Predict which image the user will like, provide it to the use and fill in our user database that the user \n",
    "    # have now seen the image, and if he/she/{} liked it.\n",
    "\n",
    "    \n",
    "    \n",
    "    jsonMetaDF = pd.read_json(\"metaDataJson.json\")\n",
    "    jsonUserDF=pd.read_json(\"jsonUser.json\")\n",
    "    userId=\"user\"+str(numUser)\n",
    "    imageDonee=[]\n",
    "    imagePasDonnes=[]\n",
    "    imageAdonne=1\n",
    "    for image in jsonMetaDF:\n",
    "        if image not in jsonUserDF[userId][\"images\"]:\n",
    "            \n",
    "            ana=analyseGlobal(numUser,image)\n",
    "            if ana==('Favorite'):\n",
    "                imageDonee.append(image)\n",
    "            else:\n",
    "                imagePasDonnes.append(image)\n",
    "    \n",
    "    if imageDonee!=[]:\n",
    "        imageAdonne=random.choice(imageDonee)\n",
    "        jsonUserDF[userId][\"images\"].append(imageAdonne)\n",
    "    else:\n",
    "        imageAdonne=random.choice(imagePasDonnes)\n",
    "        jsonUserDF[userId][\"images\"].append(imageAdonne)\n",
    "    #print(imageAdonne)\n",
    "    res = demandeFavoriteOrNot(imageAdonne,typeEnjoyer)\n",
    "    \n",
    "    \n",
    "    jsonUserDF[userId][\"result\"].append(res)\n",
    "    \n",
    "    \n",
    "    jsonUserDF.to_json(\"jsonUser.json\",orient='columns',indent=4)               \n",
    "\n",
    "\n",
    "def testNcycle(N):\n",
    "    for i in range(N):\n",
    "        cyclePropositionImage(0)\n",
    "        cyclePropositionImage(1,\"dogEnjoyer\")\n",
    "        cyclePropositionImage(2,\"fruitEnjoyer\")\n",
    "        cyclePropositionImage(3,\"lakeEnjoyer\")\n",
    "testNcycle(9)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update user preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = \"user0\" #Select user\n",
    "\n",
    "def userPreferences(userName = None):\n",
    "\n",
    "     # INPUT     : userName (string)\n",
    "     # OUTPUT    : None\n",
    "     # DESCRIPTION : Sets the user preferences in jsonUser.json. Happens for all user if no argument is given\n",
    "     \n",
    "     # Get ima\n",
    "     jsonMetaDF = pd.read_json(\"metaDataJson.json\")\n",
    "\n",
    "     # Get user like\n",
    "     userDF = pd.read_json(\"jsonUser.json\")\n",
    "\n",
    "     # Sets the user list, for which the preferences will be updated\n",
    "     userlst = []\n",
    "     if userName == None:\n",
    "          for user in userDF:\n",
    "               userlst.append(user)\n",
    "     else:\n",
    "          userlst.append(user)\n",
    "\n",
    "     # Gets all images seen and liked by the user\n",
    "     for user in userlst:\n",
    "          userImages = userDF.loc[\"images\"][user]\n",
    "          userLike = userDF.loc[\"result\"][user]\n",
    "          likedImages = []\n",
    "          for item in userImages :\n",
    "               ind = userImages.index(item)\n",
    "               if userLike[ind] == 1:\n",
    "                    likedImages.append(item)\n",
    "\n",
    "          # Gets all liked images' data\n",
    "          if len(likedImages) > 0:\n",
    "               ori = []\n",
    "               siz = []\n",
    "               tagF = []\n",
    "               colorF = []\n",
    "               for image in likedImages :\n",
    "                    ori.append(jsonMetaDF.loc[\"orientation\"][image])\n",
    "                    siz.append(jsonMetaDF.loc[\"size\"][image])\n",
    "                    tagF.append(jsonMetaDF.loc[\"tags\"][image])\n",
    "                    colorF.append(jsonMetaDF.loc[\"dom\"][image])\n",
    "\n",
    "               # Gets the data most present in the user's liked images and sets them as his preferences\n",
    "               jsonUser=json.load(open(\"jsonUser.json\"))\n",
    "               jsonUser[user][\"orientation\"]=max(ori,key = ori.count)\n",
    "               jsonUser[user][\"size\"]=max(siz,key = siz.count)\n",
    "               jsonUser[user][\"tagFav\"]=max(tagF,key = tagF.count)\n",
    "               jsonUser[user][\"colorFav\"]=max(colorF,key = colorF.count)\n",
    "               \n",
    "               jsonUserStr = json.dumps(jsonUser, indent=4)\n",
    "               f = open(\"jsonUser.json\", \"w\")\n",
    "               f.write(jsonUserStr)\n",
    "               f.close()  \n",
    "\n",
    "userPreferences() # Updates all user preferences"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show User Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user0</th>\n",
       "      <th>user1</th>\n",
       "      <th>user2</th>\n",
       "      <th>user3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>orientation</th>\n",
       "      <td>paysage</td>\n",
       "      <td>paysage</td>\n",
       "      <td>paysage</td>\n",
       "      <td>paysage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size</th>\n",
       "      <td>Grande</td>\n",
       "      <td>Petite</td>\n",
       "      <td>Grande</td>\n",
       "      <td>Grande</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tagFav</th>\n",
       "      <td>[Fruit]</td>\n",
       "      <td>[Dog]</td>\n",
       "      <td>[Fruit]</td>\n",
       "      <td>[Lake]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>colorFav</th>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               user0    user1    user2    user3\n",
       "orientation  paysage  paysage  paysage  paysage\n",
       "size          Grande   Petite   Grande   Grande\n",
       "tagFav       [Fruit]    [Dog]  [Fruit]   [Lake]\n",
       "colorFav         Red      Red      Red     Blue"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def printUserPref(userName = None):\n",
    "    # INPUT     : userName (string)\n",
    "    # OUTPUT    : The user's preferences\n",
    "    # DESCRIPTION : Shows the selected user or all user's preferences is no argument is given\n",
    "\n",
    "    if userName == None:\n",
    "        userDF = pd.read_json(\"jsonUser.json\")\n",
    "    else :\n",
    "        userDF = pd.read_json(\"jsonUser.json\")\n",
    "        userDF = userDF[userName]\n",
    "    return userDF[\"orientation\":\"colorFav\"]\n",
    "\n",
    "printUserPref() # Show all user preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fruit]    5\n",
      "[Dog]      5\n",
      "[Lake]     5\n",
      "dtype: int64\n",
      "Blue     7\n",
      "Red      7\n",
      "Green    1\n",
      "dtype: int64\n",
      "paysage     10\n",
      "portrait     4\n",
      "carre        1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Plot user liked images' stats : tags, size, ...\n",
    "def plotPref(plotLst = [\"tags\",\"dom\",\"orientation\",\"size\"],userName = None):\n",
    "    # INPUT     : plotLst (lst), userName (string)\n",
    "    # OUTPUT    : None\n",
    "    # DESCRIPTION : Plots a specific user's like image data or plots all the data from the images in the databases.\n",
    "\n",
    "    userDF = pd.read_json(\"jsonUser.json\")\n",
    "    jsonMetaDF = pd.read_json(\"metaDataJson.json\")\n",
    "\n",
    "    toPlotCount = []\n",
    "    if type(plotLst) != list:\n",
    "        plotLst = [plotLst]\n",
    "    \n",
    "    if userName == None :\n",
    "        for stat in plotLst :\n",
    "            if stat in [\"tags\",\"dom\",\"orientation\",\"size\"]:     # Stats that can be plotted are in this list\n",
    "                toPlot = []\n",
    "                for image in jsonMetaDF :\n",
    "                    toPlot.append(jsonMetaDF.loc[stat][image])\n",
    "                    \n",
    "                toPlotCount.append(pd.Series(toPlot).value_counts())\n",
    "\n",
    "    if userName != None and userName in userDF:\n",
    "        for stat in plotLst :\n",
    "            if stat in [\"tags\",\"dom\",\"orientation\",\"size\"]:     # Stats that can be plotted are in this list\n",
    "                toPlot = []\n",
    "                for image in userDF[userName][\"images\"] :\n",
    "                    toPlot.append(jsonMetaDF.loc[stat][image])\n",
    "                toPlotCount.append(pd.Series(toPlot).value_counts())\n",
    "        \n",
    "    for plotCount in toPlotCount:\n",
    "        fig = plt.figure()\n",
    "        plotCount.plot.bar()\n",
    "    plt.show()\n",
    "\n",
    "plotPref([\"tags\",\"dom\",\"orientation\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "83f73d5875a575e504ba23451a5997fea59c0c75034f677431fe9f5bc2b0207e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
