{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation des fichiers utiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image, ExifTags\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import Perceptron\n",
    "import random\n",
    "\n",
    "NOMBRE_IMAGE=141"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Demande de Json\n",
    "Nous Faisons une Requète WikiData pour demander un Json contenant le lien menant à des libres d'une certaine catégorie. Nous avons essayé plusieurs types d'images différentes :\n",
    "\n",
    "mythical creature = Q2239243<br>\n",
    "photograph = Q125191<br>\n",
    "flower = Q506<br>\n",
    "fruit = Q1364<br>\n",
    "Chien = Q144<br>\n",
    "lac  = Q23397<br>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SELECT ?image ?im WHERE {\n",
    "  ?image wdt:P31 wd:Q506.\n",
    "  ?image wdt:P18 ?im\n",
    "  }\n",
    "LIMIT 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstSources = {\"Fruit\":1364,\"Dog\":144,\"Lake\":23397}\n",
    "limitPerSources = 5\n",
    "sources = {}\n",
    "tagTemp = []\n",
    "for key,value in lstSources.items():    #Get all images to download\n",
    "    url =\"https://query.wikidata.org/sparql?query=SELECT%20%3Fimage%20%3Fim%20WHERE%20%7B%0A%20%20%3Fimage%20wdt%3AP31%20wd%3AQ\"+str(value)+\".%0A%20%20%3Fimage%20wdt%3AP18%20%3Fim%0A%20%20%7D%0ALIMIT%20\"+str(limitPerSources)+\"&format=json\"\n",
    "    response = urllib.request.urlopen(url)\n",
    "    myJson = json.loads(response.read().decode(\"utf-8\"))\n",
    "    \n",
    "    for image in myJson[\"results\"][\"bindings\"]:  #Add the tag to the image\n",
    "        image['tag'] = key\n",
    "        \n",
    "    if sources == {}:   #Make one big json containing all images\n",
    "        sources = myJson\n",
    "    else:\n",
    "        sources[\"results\"][\"bindings\"] = sources[\"results\"][\"bindings\"]+myJson[\"results\"][\"bindings\"]\n",
    "\n",
    "myJsonNormalized = pd.json_normalize(sources)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Télechargement des images ##\n",
    "A partir du Json contenant les liens menant aux images, nous lancons des requètes URLLIB pour télecharger ces images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 429: Too many requests. Please comply with the User-Agent policy to get a higher rate limit: https://meta.wikimedia.org/wiki/User-Agent_policy",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39mprint\u001b[39m(index)\n\u001b[0;32m     11\u001b[0m im \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m./images/image\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(index)\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.jpg\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> 12\u001b[0m urllib\u001b[39m.\u001b[39;49mrequest\u001b[39m.\u001b[39;49murlretrieve(imageLink, im)\n\u001b[0;32m     13\u001b[0m index \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m     15\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\augus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\urllib\\request.py:239\u001b[0m, in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    223\u001b[0m \u001b[39mRetrieve a URL into a temporary location on disk.\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[39mdata file as well as the resulting HTTPMessage object.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    237\u001b[0m url_type, path \u001b[39m=\u001b[39m _splittype(url)\n\u001b[1;32m--> 239\u001b[0m \u001b[39mwith\u001b[39;00m contextlib\u001b[39m.\u001b[39mclosing(urlopen(url, data)) \u001b[39mas\u001b[39;00m fp:\n\u001b[0;32m    240\u001b[0m     headers \u001b[39m=\u001b[39m fp\u001b[39m.\u001b[39minfo()\n\u001b[0;32m    242\u001b[0m     \u001b[39m# Just return the local path and the \"headers\" for file://\u001b[39;00m\n\u001b[0;32m    243\u001b[0m     \u001b[39m# URLs. No sense in performing a copy unless requested.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\augus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\urllib\\request.py:214\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    213\u001b[0m     opener \u001b[39m=\u001b[39m _opener\n\u001b[1;32m--> 214\u001b[0m \u001b[39mreturn\u001b[39;00m opener\u001b[39m.\u001b[39;49mopen(url, data, timeout)\n",
      "File \u001b[1;32mc:\\Users\\augus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\urllib\\request.py:523\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    521\u001b[0m \u001b[39mfor\u001b[39;00m processor \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_response\u001b[39m.\u001b[39mget(protocol, []):\n\u001b[0;32m    522\u001b[0m     meth \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(processor, meth_name)\n\u001b[1;32m--> 523\u001b[0m     response \u001b[39m=\u001b[39m meth(req, response)\n\u001b[0;32m    525\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\augus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\urllib\\request.py:632\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    629\u001b[0m \u001b[39m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[0;32m    630\u001b[0m \u001b[39m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[0;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m code \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m):\n\u001b[1;32m--> 632\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparent\u001b[39m.\u001b[39;49merror(\n\u001b[0;32m    633\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mhttp\u001b[39;49m\u001b[39m'\u001b[39;49m, request, response, code, msg, hdrs)\n\u001b[0;32m    635\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\augus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\urllib\\request.py:555\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    553\u001b[0m     http_err \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    554\u001b[0m args \u001b[39m=\u001b[39m (\u001b[39mdict\u001b[39m, proto, meth_name) \u001b[39m+\u001b[39m args\n\u001b[1;32m--> 555\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_chain(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    556\u001b[0m \u001b[39mif\u001b[39;00m result:\n\u001b[0;32m    557\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\augus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\urllib\\request.py:494\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[39mfor\u001b[39;00m handler \u001b[39min\u001b[39;00m handlers:\n\u001b[0;32m    493\u001b[0m     func \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 494\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    495\u001b[0m     \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    496\u001b[0m         \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\augus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\urllib\\request.py:747\u001b[0m, in \u001b[0;36mHTTPRedirectHandler.http_error_302\u001b[1;34m(self, req, fp, code, msg, headers)\u001b[0m\n\u001b[0;32m    744\u001b[0m fp\u001b[39m.\u001b[39mread()\n\u001b[0;32m    745\u001b[0m fp\u001b[39m.\u001b[39mclose()\n\u001b[1;32m--> 747\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparent\u001b[39m.\u001b[39;49mopen(new, timeout\u001b[39m=\u001b[39;49mreq\u001b[39m.\u001b[39;49mtimeout)\n",
      "File \u001b[1;32mc:\\Users\\augus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\urllib\\request.py:523\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    521\u001b[0m \u001b[39mfor\u001b[39;00m processor \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_response\u001b[39m.\u001b[39mget(protocol, []):\n\u001b[0;32m    522\u001b[0m     meth \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(processor, meth_name)\n\u001b[1;32m--> 523\u001b[0m     response \u001b[39m=\u001b[39m meth(req, response)\n\u001b[0;32m    525\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\augus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\urllib\\request.py:632\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    629\u001b[0m \u001b[39m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[0;32m    630\u001b[0m \u001b[39m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[0;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m code \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m):\n\u001b[1;32m--> 632\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparent\u001b[39m.\u001b[39;49merror(\n\u001b[0;32m    633\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mhttp\u001b[39;49m\u001b[39m'\u001b[39;49m, request, response, code, msg, hdrs)\n\u001b[0;32m    635\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\augus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\urllib\\request.py:555\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    553\u001b[0m     http_err \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    554\u001b[0m args \u001b[39m=\u001b[39m (\u001b[39mdict\u001b[39m, proto, meth_name) \u001b[39m+\u001b[39m args\n\u001b[1;32m--> 555\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_chain(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    556\u001b[0m \u001b[39mif\u001b[39;00m result:\n\u001b[0;32m    557\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\augus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\urllib\\request.py:494\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[39mfor\u001b[39;00m handler \u001b[39min\u001b[39;00m handlers:\n\u001b[0;32m    493\u001b[0m     func \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 494\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    495\u001b[0m     \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    496\u001b[0m         \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\augus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\urllib\\request.py:747\u001b[0m, in \u001b[0;36mHTTPRedirectHandler.http_error_302\u001b[1;34m(self, req, fp, code, msg, headers)\u001b[0m\n\u001b[0;32m    744\u001b[0m fp\u001b[39m.\u001b[39mread()\n\u001b[0;32m    745\u001b[0m fp\u001b[39m.\u001b[39mclose()\n\u001b[1;32m--> 747\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparent\u001b[39m.\u001b[39;49mopen(new, timeout\u001b[39m=\u001b[39;49mreq\u001b[39m.\u001b[39;49mtimeout)\n",
      "    \u001b[1;31m[... skipping similar frames: HTTPErrorProcessor.http_response at line 632 (2 times), OpenerDirector.open at line 523 (2 times), OpenerDirector._call_chain at line 494 (1 times), OpenerDirector.error at line 555 (1 times), HTTPRedirectHandler.http_error_302 at line 747 (1 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\augus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\urllib\\request.py:555\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    553\u001b[0m     http_err \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    554\u001b[0m args \u001b[39m=\u001b[39m (\u001b[39mdict\u001b[39m, proto, meth_name) \u001b[39m+\u001b[39m args\n\u001b[1;32m--> 555\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_chain(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    556\u001b[0m \u001b[39mif\u001b[39;00m result:\n\u001b[0;32m    557\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\augus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\urllib\\request.py:494\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[39mfor\u001b[39;00m handler \u001b[39min\u001b[39;00m handlers:\n\u001b[0;32m    493\u001b[0m     func \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 494\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    495\u001b[0m     \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    496\u001b[0m         \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\augus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\urllib\\request.py:747\u001b[0m, in \u001b[0;36mHTTPRedirectHandler.http_error_302\u001b[1;34m(self, req, fp, code, msg, headers)\u001b[0m\n\u001b[0;32m    744\u001b[0m fp\u001b[39m.\u001b[39mread()\n\u001b[0;32m    745\u001b[0m fp\u001b[39m.\u001b[39mclose()\n\u001b[1;32m--> 747\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparent\u001b[39m.\u001b[39;49mopen(new, timeout\u001b[39m=\u001b[39;49mreq\u001b[39m.\u001b[39;49mtimeout)\n",
      "File \u001b[1;32mc:\\Users\\augus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\urllib\\request.py:523\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    521\u001b[0m \u001b[39mfor\u001b[39;00m processor \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_response\u001b[39m.\u001b[39mget(protocol, []):\n\u001b[0;32m    522\u001b[0m     meth \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(processor, meth_name)\n\u001b[1;32m--> 523\u001b[0m     response \u001b[39m=\u001b[39m meth(req, response)\n\u001b[0;32m    525\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\augus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\urllib\\request.py:632\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    629\u001b[0m \u001b[39m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[0;32m    630\u001b[0m \u001b[39m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[0;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m code \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m):\n\u001b[1;32m--> 632\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparent\u001b[39m.\u001b[39;49merror(\n\u001b[0;32m    633\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mhttp\u001b[39;49m\u001b[39m'\u001b[39;49m, request, response, code, msg, hdrs)\n\u001b[0;32m    635\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\augus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\urllib\\request.py:561\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[39mif\u001b[39;00m http_err:\n\u001b[0;32m    560\u001b[0m     args \u001b[39m=\u001b[39m (\u001b[39mdict\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdefault\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mhttp_error_default\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m+\u001b[39m orig_args\n\u001b[1;32m--> 561\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_chain(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[1;32mc:\\Users\\augus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\urllib\\request.py:494\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[39mfor\u001b[39;00m handler \u001b[39min\u001b[39;00m handlers:\n\u001b[0;32m    493\u001b[0m     func \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 494\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    495\u001b[0m     \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    496\u001b[0m         \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\augus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\urllib\\request.py:641\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    640\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhttp_error_default\u001b[39m(\u001b[39mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[1;32m--> 641\u001b[0m     \u001b[39mraise\u001b[39;00m HTTPError(req\u001b[39m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 429: Too many requests. Please comply with the User-Agent policy to get a higher rate limit: https://meta.wikimedia.org/wiki/User-Agent_policy"
     ]
    }
   ],
   "source": [
    "#telechargement des images\n",
    "\n",
    "responseJson = myJsonNormalized[\"results.bindings\"]\n",
    "index=0\n",
    "lstTag=[]\n",
    "for i in range(len(responseJson[0])):   \n",
    "    imageLink = responseJson[0][i][\"im\"][\"value\"]\n",
    "    lstTag.append(responseJson[0][i][\"tag\"])\n",
    "    print(index)\n",
    "    \n",
    "    im = \"./images/image\"+str(index)+\".jpg\"\n",
    "    urllib.request.urlretrieve(imageLink, im)\n",
    "    index +=1\n",
    "\n",
    "    try:\n",
    "        imgfile = Image.open(im).convert(\"RGB\")\n",
    "    except:\n",
    "        index-=1\n",
    "        del lstTag[-1]\n",
    "        print(\"pas fonctionne\")\n",
    "    \n",
    "NOMBRE_IMAGE=index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Récupération des métadonnées\n",
    "L'obhectif de cette partie est de récupérer les informations des images, nous récupérons les images suivantes :<br>\n",
    "1. Récupération Exif utiles\n",
    "2. Récupération couleurs dominantes (K-means)\n",
    "3. Récupération taille des images\n",
    "4. Détermination portrait ou paysage\n",
    "\n",
    "Apres cela, nous avons creer un Json **metaDataJson.json** contenant toutes les informationns precedentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gabin\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:887: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 4096 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l'image 0 ne peut pas etre ouverte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gabin\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:887: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 4096 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l'image 1 ne peut pas etre ouverte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gabin\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:887: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 4096 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l'image 2 ne peut pas etre ouverte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gabin\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:887: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 4096 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l'image 3 ne peut pas etre ouverte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gabin\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:887: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 4096 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l'image 4 ne peut pas etre ouverte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gabin\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:887: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 4096 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l'image 5 ne peut pas etre ouverte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gabin\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:887: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 4096 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n",
      "c:\\Users\\gabin\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:887: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 4096 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l'image 6 ne peut pas etre ouverte\n",
      "l'image 7 ne peut pas etre ouverte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gabin\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:887: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 4096 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l'image 8 ne peut pas etre ouverte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gabin\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:887: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 4096 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l'image 9 ne peut pas etre ouverte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gabin\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:887: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 4096 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l'image 10 ne peut pas etre ouverte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gabin\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:887: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 4096 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l'image 11 ne peut pas etre ouverte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gabin\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:887: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 4096 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l'image 12 ne peut pas etre ouverte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gabin\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:887: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 4096 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l'image 13 ne peut pas etre ouverte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gabin\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:887: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 4096 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l'image 14 ne peut pas etre ouverte\n"
     ]
    }
   ],
   "source": [
    "# Récupération des métadonnées\n",
    "\n",
    "metaData ={}\n",
    "for i in range(NOMBRE_IMAGE):\n",
    "    im = \"./images/image\"+str(i)+\".jpg\"\n",
    "    #try:\n",
    "    imgfile = Image.open(im).convert(\"RGB\")\n",
    "\n",
    "    #Recupération Exif utiles\n",
    "    exif = {}\n",
    "    exifCritere= (\"Model\",\"Make\",\"ImageDescription\",\"ExposureTime\",\"GPSInfo\",\"ISO\",\"DateTimeOriginal\")\n",
    "    for k,v in  imgfile.getexif().items() :\n",
    "        if k in ExifTags.TAGS :\n",
    "            if ExifTags.TAGS[k] in exifCritere:\n",
    "                exif = {ExifTags.TAGS[k]:v}\n",
    "\n",
    "    # Recupération couleurs dominantes (K-means)\n",
    "    numarray = np.array(imgfile.getdata(), np.uint8)\n",
    "    clusters  = MiniBatchKMeans(n_clusters=3, n_init=2) \n",
    "    clusters.fit(numarray)\n",
    "    L = clusters.cluster_centers_.astype(int).tolist()\n",
    "    if L[0][0]>L[0][1] and L[0][0]>L[0][2]:\n",
    "        domColor = \"Red\"\n",
    "    elif L[0][1]>L[0][0] and L[0][1]>L[0][2]:\n",
    "        domColor = \"Green\"\n",
    "    elif L[0][2]>L[0][0] and L[0][2]>L[0][1]:\n",
    "        domColor = \"Blue\"\n",
    "    elif L[0][0]==L[0][1]==L[0][2]:\n",
    "        domColor = \"White\"\n",
    "    else:\n",
    "        domColor = \"None\"\n",
    "\n",
    "    # Recupération taille des images\n",
    "    width = imgfile.width\n",
    "    height = imgfile.height\n",
    "    mode = imgfile.mode\n",
    "\n",
    "    # Détermination portrait ou paysage\n",
    "    if abs(1-width/height)<0.1 :\n",
    "        orientation='carre' \n",
    "    elif width>height:\n",
    "        orientation='paysage'\n",
    "    else: \n",
    "        orientation=\"portrait\"\n",
    "\n",
    "    # Get image size (big, small, ...)\n",
    "    pixelCount = width * height\n",
    "\n",
    "    if pixelCount >= 1920*1080:\n",
    "        size = \"Grande\"\n",
    "    elif pixelCount >= 1280*720:\n",
    "        size = \"Moyenne\"\n",
    "    elif pixelCount >= 720*480:\n",
    "        size = \"Petite\"\n",
    "    elif pixelCount < 720*480:\n",
    "        size = \"Vignette\"\n",
    "    else:\n",
    "        size = \"WTF\"\n",
    "\n",
    "    metaData[\"image\"+str(i)] = { \"width\" : width, \"height\": height, \"exif\": exif, \"mode\":mode, \"tags\":[lstTag[i]], \"couleurs\":L, \"orientation\":orientation, \"size\":size, \"dom\":domColor}\n",
    "    #except Exception:\n",
    "    print(\"l'image \"+str(i) +\" ne peut pas etre ouverte\")\n",
    "metaData\n",
    "\n",
    "metaDatajson = json.dumps(metaData)\n",
    "f = open(\"metaDataJson.json\", \"w\")\n",
    "f.write(metaDatajson)\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse\n",
    "\n",
    "Consiste en 2 parties, l'analyse couleur, pour savoir si l'image proposée à des couleurs proche des images aimées par l'utilisateur. Et l'analyse globale qui utilise un arbre de décision et les paramètres de metadataJson pour décider si l'image peut etre proposée ou non à l'utilisateur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "\n",
    "def analyseCouleur(numUser,numImage): \n",
    "    jsonUser=json.load(open(\"jsonUser.json\"))\n",
    "    jsonMeta=json.load(open(\"metaDatajson.json\"))\n",
    "    couleurs=[]\n",
    "    \n",
    "\n",
    "    \n",
    "    jsonUserDF=pd.read_json(\"jsonUser.json\")\n",
    "    jsonMetaDF=pd.read_json(\"metaDataJson.json\")\n",
    "    userId=\"user\"+str(numUser)\n",
    "    for image in jsonUserDF[userId][\"images\"]:\n",
    "        couleurs.append(flatten(jsonMetaDF[image][\"couleurs\"]))\n",
    "    \n",
    "\n",
    "    numarray=np.array(couleurs)\n",
    "    like=np.array(jsonUserDF[userId][\"result\"])\n",
    "  \n",
    "    # modele des couleurs\n",
    "    percep = Perceptron(max_iter=1000)\n",
    "    percep.fit(numarray, like)\n",
    "\n",
    "    # prediction\n",
    "    nomImage=str(numImage)\n",
    "    x_predict = np.array([flatten(jsonMetaDF[image][\"couleurs\"])])\n",
    "    y_predict = percep.predict(x_predict)\n",
    "\n",
    "    return y_predict[0]\n",
    "print(analyseCouleur(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NotFavorite'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "def analyseGlobal(userIndex,numImage):\n",
    "\n",
    "    # Get image data\n",
    "    jsonMetaDF = pd.read_json(\"metaDataJson.json\")\n",
    "    lstTags = jsonMetaDF.loc[\"tags\"].to_list()\n",
    "    lstOrientation = jsonMetaDF.loc[\"orientation\"].to_list()\n",
    "\n",
    "    # Get user like\n",
    "    userDF = pd.read_json(\"jsonUser.json\")\n",
    "    userImages = userDF.loc[\"images\"][userIndex]\n",
    "    userLike = userDF.loc[\"result\"][userIndex]\n",
    "\n",
    "    data = []\n",
    "    for item in userImages:\n",
    "        imageDesc = []\n",
    "        #imageDesc.append(jsonMetaDF.loc[\"couleurs\"][item])\n",
    "        imageDesc.append(jsonMetaDF.loc[\"dom\"][item])\n",
    "        imageDesc.append(jsonMetaDF.loc[\"tags\"][item][0])\n",
    "        imageDesc.append(jsonMetaDF.loc[\"size\"][item])\n",
    "        imageDesc.append(jsonMetaDF.loc[\"orientation\"][item])\n",
    "        imageDesc.append(analyseCouleur(userIndex,numImage))\n",
    "        data.append(imageDesc)\n",
    "\n",
    "\n",
    "    result = [None]*len(userImages)\n",
    "    for item in jsonMetaDF:\n",
    "        if item in userImages:\n",
    "            ind = userImages.index(item)\n",
    "            if userLike[ind] == 1:\n",
    "                result[ind]=\"Favorite\"\n",
    "            else :\n",
    "                result[ind]=\"NotFavorite\"\n",
    "\n",
    "    # creating dataframes\n",
    "    dataframe = pd.DataFrame(data, columns=[\"dom\", \"tags\", \"size\", \"orientation\",\"likedColor\"])\n",
    "    resultframe = pd.DataFrame(result, columns=[\"favorite\"])\n",
    "\n",
    "    #print(dataframe[\"dom\"])\n",
    "\n",
    "    le1 = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "    dataframe[\"dom\"] = le1.fit_transform(dataframe[\"dom\"].values.reshape(-1,1))\n",
    "\n",
    "    le2 = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "    dataframe[\"tags\"] = le2.fit_transform(dataframe[\"tags\"].values.reshape(-1,1))\n",
    "\n",
    "    le3 = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "    dataframe[\"size\"] = le3.fit_transform(dataframe[\"size\"].values.reshape(-1,1))\n",
    "\n",
    "    le4 = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "    dataframe[\"orientation\"] = le4.fit_transform(dataframe[\"orientation\"].values.reshape(-1,1))\n",
    "\n",
    "    le5 = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "    dataframe[\"likedColor\"] = le5.fit_transform(dataframe[\"likedColor\"].values.reshape(-1,1))\n",
    "\n",
    "    le6 = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "    resultframe[\"favorite\"] = le6.fit_transform(resultframe[\"favorite\"].values.reshape(-1,1))\n",
    "    \n",
    "    # # generating numerical labels\n",
    "    # le1 = LabelEncoder()\n",
    "    # dataframe[\"dom\"] = le1.fit_transform(dataframe[\"dom\"])\n",
    "\n",
    "    # le2 = LabelEncoder()\n",
    "    # dataframe[\"tags\"] = le2.fit_transform(dataframe[\"tags\"])\n",
    "\n",
    "    # le3 = LabelEncoder()\n",
    "    # dataframe[\"size\"] = le3.fit_transform(dataframe[\"size\"])\n",
    "\n",
    "    # le4 = LabelEncoder()\n",
    "    # dataframe[\"orientation\"] = le4.fit_transform(dataframe[\"orientation\"])\n",
    "\n",
    "    # le5 = LabelEncoder()\n",
    "    # resultframe[\"favorite\"] = le5.fit_transform(resultframe[\"favorite\"])\n",
    "\n",
    "    # Use of decision tree classifiers\n",
    "    dtc = tree.DecisionTreeClassifier()\n",
    "    dtc = dtc.fit(dataframe.values, resultframe)\n",
    "\n",
    "    #print(dtc.feature_importances_)\n",
    "    #prediction\n",
    "    #print(dataframe[\"orientation\"].to_list())\n",
    "    \n",
    "    prediction = dtc.predict(np.array([\n",
    "        \n",
    "            le1.transform(pd.DataFrame([\"Blue\"], columns=[\"couleur\"]))[0],\n",
    "            le2.transform(pd.DataFrame([\"Dog\"], columns=[\"tag\"]))[0],\n",
    "            le3.transform(pd.DataFrame([\"Grande\"], columns=[\"size\"]))[0],\n",
    "            le4.transform(pd.DataFrame([\"portrait\"], columns=[\"orientation\"]))[0],\n",
    "            le5.transform(pd.DataFrame([\"1\"], columns=[\"likedColor\"]))[0],\n",
    "        \n",
    "    ]).reshape(1,-1))\n",
    "    #print(le6.inverse_transform(prediction.reshape(-1,1)))\n",
    "    return le6.inverse_transform(prediction.reshape(-1,1)).tolist()[0][0]\n",
    "    #print(dtc.feature_importances_)\n",
    "    #createUser(\"myName\", \"effef\")\n",
    "analyseGlobal(1,1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Systeme de recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user4\n"
     ]
    }
   ],
   "source": [
    "def createUser(nom, prenom, images,like):\n",
    "    jsonUser=json.load(open(\"jsonUser.json\"))\n",
    "    \n",
    "    userId=\"user\"+str(len(jsonUser))\n",
    "    jsonUser[userId]={\"nom\" : nom,\"prenom\" : prenom, \"images\":[],\"result\":[],\"year\":\"\",\"size\":\"\",\"tagFav\":\"\",\"orientation\":\"\",\"couleursFav\":\"\"\n",
    "        \n",
    "    }\n",
    "    \n",
    "    jsonUserStr = json.dumps(jsonUser, indent=4)\n",
    "    f = open(\"jsonUser.json\", \"w\")\n",
    "    f.write(jsonUserStr)\n",
    "    f.close()  \n",
    "createUser(\"myName\", \"effef\",1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image1\n",
      "                                          user0  \\\n",
      "nom                              Grosbraquemard   \n",
      "prenom                                    Kevin   \n",
      "images       [image1, image10, image12, image8]   \n",
      "result                             [1, 0, 0, 1]   \n",
      "year                                              \n",
      "orientation                                       \n",
      "size                                              \n",
      "tagFav                                            \n",
      "colorFav                                          \n",
      "couleursFav                                None   \n",
      "\n",
      "                                                         user1  \\\n",
      "nom                                                      Queue   \n",
      "prenom                                                    Jean   \n",
      "images       [image2, image7, image9, image6, image13, [ima...   \n",
      "result                                      [1, 0, 0, 1, 0, 0]   \n",
      "year                                                             \n",
      "orientation                                                      \n",
      "size                                                             \n",
      "tagFav                                                           \n",
      "colorFav                                                         \n",
      "couleursFav                                               None   \n",
      "\n",
      "                                          user2  \\\n",
      "nom                                        Teub   \n",
      "prenom                               Frédérique   \n",
      "images       [image6, image12, image8, image10]   \n",
      "result                             [1, 0, 0, 1]   \n",
      "year                                              \n",
      "orientation                                       \n",
      "size                                              \n",
      "tagFav                                            \n",
      "colorFav                                          \n",
      "couleursFav                                None   \n",
      "\n",
      "                                        user3   user4  \n",
      "nom                               De la verge  myName  \n",
      "prenom                                Titouan   effef  \n",
      "images       [image1, image5, image4, image2]      []  \n",
      "result                           [1, 0, 0, 1]      []  \n",
      "year                                                   \n",
      "orientation                                            \n",
      "size                                                   \n",
      "tagFav                                                 \n",
      "colorFav                                         None  \n",
      "couleursFav                              None          \n"
     ]
    }
   ],
   "source": [
    "def demandeFavoriteOrNot(numUser,nomImage,typeEnjoyer=\"likeAll\"):\n",
    "    jsonMetaDF = pd.read_json(\"metaDataJson.json\")\n",
    "   \n",
    "    if typeEnjoyer ==\"likeAll\":\n",
    "        return 'Favorite'\n",
    "    elif typeEnjoyer ==\"dogEnjoyer\":\n",
    "        print(nomImage)\n",
    "        #print(jsonMetaDF[nomImage])\n",
    "        if \"Dog\" in jsonMetaDF[nomImage][\"tags\"]:\n",
    "            return 'Favorite'\n",
    "        else:\n",
    "            return 'NotFavorite'\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def cyclePropositionImage(numUser,typeEnjoyer):\n",
    "    userId=\"user\"+str(numUser)\n",
    "    jsonMetaDF = pd.read_json(\"metaDataJson.json\")\n",
    "    jsonUserDF=pd.read_json(\"jsonUser.json\")\n",
    "    imageDonee=[]\n",
    "    imagePasDonnes=[]\n",
    "    imageAdonne=1\n",
    "    for image in jsonMetaDF:\n",
    "        if image not in jsonUserDF[userId][\"images\"]:\n",
    "            \n",
    "            ana=analyseGlobal(numUser,image)\n",
    "            if ana==('Favorite'):\n",
    "                imageDonee.append(image)\n",
    "            else:\n",
    "                imagePasDonnes.append(image)\n",
    "    \n",
    "    if imageDonee!=[]:\n",
    "        imageAdonne=random.choice(imageDonee)\n",
    "        print(imageAdonne)\n",
    "        jsonUserDF[userId][\"images\"].append(imageAdonne)\n",
    "    else:\n",
    "        imageAdonne=random.choice(imagePasDonnes)\n",
    "        jsonUserDF[userId][\"images\"].append(imagePasDonnes)\n",
    "    #print(imageAdonne)\n",
    "    res = demandeFavoriteOrNot(numUser,imageAdonne,typeEnjoyer)\n",
    "    \n",
    "    if res=='Favorite':\n",
    "        jsonUserDF[userId][\"result\"].append(1)\n",
    "    elif res=='NotFavorite':\n",
    "        jsonUserDF[userId][\"result\"].append(0)\n",
    "    else:\n",
    "        print(\"Error : demandeFavoriteOrNot does not return expected results\") \n",
    "    print(jsonUserDF)\n",
    "    jsonUserDF.to_json(\"jsonUser.json\",orient='columns',indent=4)               \n",
    "\n",
    "cyclePropositionImage(1,\"dogEnjoyer\")\n",
    "\n",
    "def testNcycle(N):\n",
    "    for i in range(N):\n",
    "        cyclePropositionImage(1,\"dogEnjoyer\")\n",
    "        analyseGlobal(1,3)\n",
    "        #cyclePropositionImage(2,\"likeAll\")\n",
    "        #analyseGlobal(3,9)\n",
    "#testNcycle(9)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brouillon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'numUser' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-1a980af361ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mjsonUser\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"jsonUser.json\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnumUser\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mjsonMeta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"metaDatajson.json\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcouleurs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdataArray\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mjsonMeta\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'numUser' is not defined"
     ]
    }
   ],
   "source": [
    " \n",
    "jsonUser=json.load(open(\"jsonUser.json\"))[numUser]\n",
    "jsonMeta=json.load(open(\"metaDatajson.json\"))\n",
    "couleurs=[]\n",
    "dataArray=[]\n",
    "for image in jsonMeta:\n",
    "    if image in jsonUser[\"data\"][\"image\"]:\n",
    "    #image correspond maintenant aux informations des images testees\n",
    "        L=[]\n",
    "        dataImage=[]\n",
    "        if jsonMeta[image][\"tags\"]==[]:\n",
    "            dataImage.append(None)\n",
    "        else:\n",
    "            dataImage.append(jsonMeta[image][\"tags\"])\n",
    "        dataImage.append(jsonMeta[image][\"orientation\"])\n",
    "        dataImage.append(jsonMeta[image][\"width\"])\n",
    "\n",
    "        for couleur in jsonMeta[image][\"couleurs\"]:\n",
    "            for valeurRBG in couleur:\n",
    "                L.append(valeurRBG)\n",
    "        dataArray.append(dataImage)\n",
    "        couleurs.append(L)\n",
    "print(dataArray)\n",
    "numarray=np.array(couleurs)\n",
    "like=np.array(jsonUser[\"data\"][\"resultat\"])\n",
    "    \n",
    "#modele des couleurs\n",
    "percep = Perceptron(max_iter=1000)\n",
    "percep.fit(numarray, like)\n",
    "    \n",
    "\n",
    "#modele arbre de decision generale\n",
    "dataFrame = pd.DataFrame(dataArray, columns=[\"tags\", \"orientation\", \"mode\"])\n",
    "likeFrame=pd.DataFrame(like,columns=['like'])\n",
    "\n",
    "\n",
    "le1 = LabelEncoder()\n",
    "dataFrame['tags'] = le1.fit_transform(dataFrame['tags'])\n",
    "\n",
    "le2 = LabelEncoder()\n",
    "dataFrame['orientation'] = le2.fit_transform(dataFrame['orientation'])\n",
    "\n",
    "le3 = LabelEncoder()\n",
    "dataFrame['mode'] = le3.fit_transform(dataFrame['mode'])\n",
    "\n",
    "le4 = LabelEncoder()\n",
    "likeFrame['like'] = le4.fit_transform(likeFrame['like'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "83f73d5875a575e504ba23451a5997fea59c0c75034f677431fe9f5bc2b0207e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
