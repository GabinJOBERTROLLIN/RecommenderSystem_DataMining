{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation des fichiers utiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image, ExifTags\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import Perceptron\n",
    "import random\n",
    "\n",
    "NOMBRE_IMAGE=141"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Demande de Json\n",
    "Nous Faisons une Requète WikiData pour demander un Json contenant le lien menant à des libres d'une certaine catégorie. Nous avons essayé plusieurs types d'images différentes :\n",
    "\n",
    "mythical creature = Q2239243<br>\n",
    "photograph = Q125191<br>\n",
    "flower = Q506<br>\n",
    "fruit = Q1364<br>\n",
    "Chien = Q144<br>\n",
    "lac  = Q23397<br>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SELECT ?image ?im WHERE {\n",
    "  ?image wdt:P31 wd:Q506.\n",
    "  ?image wdt:P18 ?im\n",
    "  }\n",
    "LIMIT 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstSources = {\"Fruit\":1364,\"Dog\":144,\"Lake\":23397}\n",
    "limitPerSources = 5\n",
    "sources = {}\n",
    "tagTemp = []\n",
    "for key,value in lstSources.items():    #Get all images to download\n",
    "    url =\"https://query.wikidata.org/sparql?query=SELECT%20%3Fimage%20%3Fim%20WHERE%20%7B%0A%20%20%3Fimage%20wdt%3AP31%20wd%3AQ\"+str(value)+\".%0A%20%20%3Fimage%20wdt%3AP18%20%3Fim%0A%20%20%7D%0ALIMIT%20\"+str(limitPerSources)+\"&format=json\"\n",
    "    response = urllib.request.urlopen(url)\n",
    "    myJson = json.loads(response.read().decode(\"utf-8\"))\n",
    "    \n",
    "    for image in myJson[\"results\"][\"bindings\"]:  #Add the tag to the image\n",
    "        image['tag'] = key\n",
    "        \n",
    "    if sources == {}:   #Make one big json containing all images\n",
    "        sources = myJson\n",
    "    else:\n",
    "        sources[\"results\"][\"bindings\"] = sources[\"results\"][\"bindings\"]+myJson[\"results\"][\"bindings\"]\n",
    "\n",
    "myJsonNormalized = pd.json_normalize(sources)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Télechargement des images ##\n",
    "A partir du Json contenant les liens menant aux images, nous lancons des requètes URLLIB pour télecharger ces images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "#telechargement des images\n",
    "\n",
    "responseJson = myJsonNormalized[\"results.bindings\"]\n",
    "index=0\n",
    "lstTag=[]\n",
    "for i in range(len(responseJson[0])):   \n",
    "    imageLink = responseJson[0][i][\"im\"][\"value\"]\n",
    "    lstTag.append(responseJson[0][i][\"tag\"])\n",
    "    print(index)\n",
    "    \n",
    "    im = \"./images/image\"+str(index)+\".jpg\"\n",
    "    urllib.request.urlretrieve(imageLink, im)\n",
    "    index +=1\n",
    "\n",
    "    try:\n",
    "        imgfile = Image.open(im).convert(\"RGB\")\n",
    "    except:\n",
    "        index-=1\n",
    "        del lstTag[-1]\n",
    "        print(\"pas fonctionne\")\n",
    "    \n",
    "NOMBRE_IMAGE=index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Récupération des métadonnées\n",
    "L'obhectif de cette partie est de récupérer les informations des images, nous récupérons les images suivantes :<br>\n",
    "1. Récupération Exif utiles\n",
    "2. Récupération couleurs dominantes (K-means)\n",
    "3. Récupération taille des images\n",
    "4. Détermination portrait ou paysage\n",
    "\n",
    "Apres cela, nous avons creer un Json **metaDataJson.json** contenant toutes les informationns precedentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération des métadonnées\n",
    "\n",
    "metaData ={}\n",
    "for i in range(NOMBRE_IMAGE):\n",
    "    im = \"./images/image\"+str(i)+\".jpg\"\n",
    "    try:\n",
    "        imgfile = Image.open(im).convert(\"RGB\")\n",
    "\n",
    "        #Recupération Exif utiles\n",
    "        exif = {}\n",
    "        exifCritere= (\"Model\",\"Make\",\"ImageDescription\",\"ExposureTime\",\"GPSInfo\",\"ISO\",\"DateTimeOriginal\")\n",
    "        for k,v in  imgfile.getexif().items() :\n",
    "            if k in ExifTags.TAGS :\n",
    "                if ExifTags.TAGS[k] in exifCritere:\n",
    "                    exif = {ExifTags.TAGS[k]:v}\n",
    "\n",
    "        # Recupération couleurs dominantes (K-means)\n",
    "        numarray = np.array(imgfile.getdata(), np.uint8)\n",
    "        clusters  = MiniBatchKMeans(n_clusters=3, n_init=2) \n",
    "        clusters.fit(numarray)\n",
    "        L = clusters.cluster_centers_.astype(int).tolist()\n",
    "        if L[0][0]>L[0][1] and L[0][0]>L[0][2]:\n",
    "            domColor = \"Red\"\n",
    "        elif L[0][1]>L[0][0] and L[0][1]>L[0][2]:\n",
    "            domColor = \"Green\"\n",
    "        elif L[0][2]>L[0][0] and L[0][2]>L[0][1]:\n",
    "            domColor = \"Blue\"\n",
    "        elif L[0][0]==L[0][1]==L[0][2]:\n",
    "            domColor = \"White\"\n",
    "        else:\n",
    "            domColor = \"None\"\n",
    "\n",
    "        # Recupération taille des images\n",
    "        width = imgfile.width\n",
    "        height = imgfile.height\n",
    "        mode = imgfile.mode\n",
    "\n",
    "        # Détermination portrait ou paysage\n",
    "        if abs(1-width/height)<0.1 :\n",
    "            orientation='carre' \n",
    "        elif width>height:\n",
    "            orientation='paysage'\n",
    "        else: \n",
    "            orientation=\"portrait\"\n",
    "\n",
    "        # Get image size (big, small, ...)\n",
    "        pixelCount = width * height\n",
    "\n",
    "        if pixelCount >= 1920*1080:\n",
    "            size = \"Grande\"\n",
    "        elif pixelCount >= 1280*720:\n",
    "            size = \"Moyenne\"\n",
    "        elif pixelCount >= 720*480:\n",
    "            size = \"Petite\"\n",
    "        elif pixelCount < 720*480:\n",
    "            size = \"Vignette\"\n",
    "        else:\n",
    "            size = \"WTF\"\n",
    "\n",
    "        metaData[\"image\"+str(i)] = { \"width\" : width, \"height\": height, \"exif\": exif, \"mode\":mode, \"tags\":[lstTag[i]], \"couleurs\":L, \"orientation\":orientation, \"size\":size, \"dom\":domColor}\n",
    "    except Exception:\n",
    "        print(\"l'image \"+str(i) +\" ne peut pas etre ouverte\")\n",
    "metaData\n",
    "\n",
    "metaDatajson = json.dumps(metaData)\n",
    "f = open(\"metaDataJson.json\", \"w\")\n",
    "f.write(metaDatajson)\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse\n",
    "\n",
    "Consiste en 2 parties, l'analyse couleur, pour savoir si l'image proposée à des couleurs proche des images aimées par l'utilisateur. Et l'analyse globale qui utilise un arbre de décision et les paramètres de metadataJson pour décider si l'image peut etre proposée ou non à l'utilisateur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "\n",
    "def analyseCouleur(numUser,numImage): \n",
    "    couleurs=[]\n",
    "    \n",
    "\n",
    "    \n",
    "    jsonUserDF=pd.read_json(\"jsonUser.json\")\n",
    "    jsonMetaDF=pd.read_json(\"metaDataJson.json\")\n",
    "    userId=\"user\"+str(numUser)\n",
    "    for image in jsonUserDF[userId][\"images\"]:\n",
    "        couleurs.append(flatten(jsonMetaDF[image][\"couleurs\"]))\n",
    "    \n",
    "\n",
    "    numarray=np.array(couleurs)\n",
    "    like=np.array(jsonUserDF[userId][\"result\"])\n",
    "  \n",
    "    # modele des couleurs\n",
    "    percep = Perceptron(max_iter=1000)\n",
    "    percep.fit(numarray, like)\n",
    "\n",
    "    # prediction\n",
    "    nomImage=str(numImage)\n",
    "    x_predict = np.array([flatten(jsonMetaDF[nomImage][\"couleurs\"])])\n",
    "    y_predict = percep.predict(x_predict)\n",
    "\n",
    "    return y_predict[0]\n",
    "\n",
    "analyseCouleur(1,\"image1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.66666667 0.         0.33333333 0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\augus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but OrdinalEncoder was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\augus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but OrdinalEncoder was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\augus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but OrdinalEncoder was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\augus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but OrdinalEncoder was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\augus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but OrdinalEncoder was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Favorite'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "def analyseGlobal(userIndex,nomImage):\n",
    "\n",
    "    # Get image data\n",
    "    jsonMetaDF = pd.read_json(\"metaDataJson.json\")\n",
    "\n",
    "    # Get user like\n",
    "    userDF = pd.read_json(\"jsonUser.json\")\n",
    "    userImages = userDF.loc[\"images\"][userIndex]\n",
    "    userLike = userDF.loc[\"result\"][userIndex]\n",
    "\n",
    "    data = []\n",
    "    for item in userImages:\n",
    "        imageDesc = []\n",
    "        #imageDesc.append(jsonMetaDF.loc[\"couleurs\"][item])\n",
    "        imageDesc.append(jsonMetaDF.loc[\"dom\"][item])\n",
    "        imageDesc.append(jsonMetaDF.loc[\"tags\"][item][0])\n",
    "        imageDesc.append(jsonMetaDF.loc[\"size\"][item])\n",
    "        imageDesc.append(jsonMetaDF.loc[\"orientation\"][item])\n",
    "        imageDesc.append(analyseCouleur(userIndex,item))\n",
    "        data.append(imageDesc)\n",
    "\n",
    "\n",
    "    result = [None]*len(userImages)\n",
    "    for item in jsonMetaDF:\n",
    "        if item in userImages:\n",
    "            ind = userImages.index(item)\n",
    "            if userLike[ind] == 1:\n",
    "                result[ind]=\"Favorite\"\n",
    "            else :\n",
    "                result[ind]=\"NotFavorite\"\n",
    "\n",
    "    # creating dataframes\n",
    "    dataframe = pd.DataFrame(data, columns=[\"dom\", \"tags\", \"size\", \"orientation\",\"likedColor\"])\n",
    "    resultframe = pd.DataFrame(result, columns=[\"favorite\"])\n",
    "\n",
    "    #print(dataframe[\"dom\"])\n",
    "\n",
    "    le1 = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "    dataframe[\"dom\"] = le1.fit_transform(dataframe[\"dom\"].values.reshape(-1,1))\n",
    "\n",
    "    le2 = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "    dataframe[\"tags\"] = le2.fit_transform(dataframe[\"tags\"].values.reshape(-1,1))\n",
    "\n",
    "    le3 = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "    dataframe[\"size\"] = le3.fit_transform(dataframe[\"size\"].values.reshape(-1,1))\n",
    "\n",
    "    le4 = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "    dataframe[\"orientation\"] = le4.fit_transform(dataframe[\"orientation\"].values.reshape(-1,1))\n",
    "\n",
    "    le5 = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "    dataframe[\"likedColor\"] = le5.fit_transform(dataframe[\"likedColor\"].values.reshape(-1,1))\n",
    "\n",
    "    le6 = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "    resultframe[\"favorite\"] = le6.fit_transform(resultframe[\"favorite\"].values.reshape(-1,1))\n",
    "    \n",
    "    # # generating numerical labels\n",
    "    # le1 = LabelEncoder()\n",
    "    # dataframe[\"dom\"] = le1.fit_transform(dataframe[\"dom\"])\n",
    "\n",
    "    # le2 = LabelEncoder()\n",
    "    # dataframe[\"tags\"] = le2.fit_transform(dataframe[\"tags\"])\n",
    "\n",
    "    # le3 = LabelEncoder()\n",
    "    # dataframe[\"size\"] = le3.fit_transform(dataframe[\"size\"])\n",
    "\n",
    "    # le4 = LabelEncoder()\n",
    "    # dataframe[\"orientation\"] = le4.fit_transform(dataframe[\"orientation\"])\n",
    "\n",
    "    # le5 = LabelEncoder()\n",
    "    # resultframe[\"favorite\"] = le5.fit_transform(resultframe[\"favorite\"])\n",
    "\n",
    "    # Use of decision tree classifiers\n",
    "    dtc = tree.DecisionTreeClassifier()\n",
    "    dtc = dtc.fit(dataframe.values, resultframe)\n",
    "\n",
    "\n",
    "    #prediction\n",
    "\n",
    "    colorP = jsonMetaDF.loc[\"dom\"][nomImage]\n",
    "    tagsP = jsonMetaDF.loc[\"tags\"][nomImage]\n",
    "    sizeP = jsonMetaDF.loc[\"size\"][nomImage]\n",
    "    orientationP = jsonMetaDF.loc[\"orientation\"][nomImage]\n",
    "    colorLikeP = analyseCouleur(userIndex,nomImage)\n",
    "    \n",
    "    prediction = dtc.predict(np.array([\n",
    "        \n",
    "            le1.transform(pd.DataFrame([colorP], columns=[\"couleur\"]))[0],\n",
    "            le2.transform(pd.DataFrame([tagsP], columns=[\"tag\"]))[0],\n",
    "            le3.transform(pd.DataFrame([sizeP], columns=[\"size\"]))[0],\n",
    "            le4.transform(pd.DataFrame([orientationP], columns=[\"orientation\"]))[0],\n",
    "            le5.transform(pd.DataFrame([colorLikeP], columns=[\"likedColor\"]))[0],\n",
    "        \n",
    "    ]).reshape(1,-1))\n",
    "    \n",
    "    print(dtc.feature_importances_)\n",
    "    return le6.inverse_transform(prediction.reshape(-1,1)).tolist()[0][0]\n",
    "    \n",
    "#TODO Vérifier que likedColor pas toujours le seul critère déterminant\n",
    "analyseGlobal(1,\"image1\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Systeme de recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createUser(nom, prenom, images = None,like = None):\n",
    "    jsonUser=json.load(open(\"jsonUser.json\"))\n",
    "    if images == None:\n",
    "        firstImage = \"image\" + str(random.randint(0,NOMBRE_IMAGE-1))\n",
    "        images = [firstImage]\n",
    "        like = [random.randint(0,1)]\n",
    "    \n",
    "    userId=\"user\"+str(len(jsonUser))\n",
    "    if len(images) == len(like) :\n",
    "        jsonUser[userId]={\"nom\" : nom,\"prenom\" : prenom, \"images\":images,\"result\":like,\"year\":\"\",\"size\":\"\",\"tagFav\":\"\",\"orientation\":\"\",\"couleursFav\":\"\"}\n",
    "    else :\n",
    "        print(\"Entrez des listes d'images et de like de taille égale svp\")\n",
    "    \n",
    "    \n",
    "    jsonUserStr = json.dumps(jsonUser, indent=4)\n",
    "    f = open(\"jsonUser.json\", \"w\")\n",
    "    f.write(jsonUserStr)\n",
    "    f.close()  \n",
    "createUser(\"Jean\", \"Culetamère\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 53\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[39mprint\u001b[39m(jsonUserDF)\n\u001b[0;32m     51\u001b[0m     jsonUserDF\u001b[39m.\u001b[39mto_json(\u001b[39m\"\u001b[39m\u001b[39mjsonUser.json\u001b[39m\u001b[39m\"\u001b[39m,orient\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m'\u001b[39m,indent\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m)               \n\u001b[1;32m---> 53\u001b[0m cyclePropositionImage(\u001b[39m6\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mdogEnjoyer\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     55\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtestNcycle\u001b[39m(N):\n\u001b[0;32m     56\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(N):\n",
      "Cell \u001b[1;32mIn[51], line 28\u001b[0m, in \u001b[0;36mcyclePropositionImage\u001b[1;34m(numUser, typeEnjoyer)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[39mfor\u001b[39;00m image \u001b[39min\u001b[39;00m jsonMetaDF:\n\u001b[0;32m     26\u001b[0m     \u001b[39mif\u001b[39;00m image \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m jsonUserDF[userId][\u001b[39m\"\u001b[39m\u001b[39mimages\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m---> 28\u001b[0m         ana\u001b[39m=\u001b[39manalyseGlobal(numUser,image)\n\u001b[0;32m     29\u001b[0m         \u001b[39mif\u001b[39;00m ana\u001b[39m==\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mFavorite\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     30\u001b[0m             imageDonee\u001b[39m.\u001b[39mappend(image)\n",
      "Cell \u001b[1;32mIn[49], line 40\u001b[0m, in \u001b[0;36manalyseGlobal\u001b[1;34m(userIndex, nomImage)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[39m#print(dataframe[\"dom\"])\u001b[39;00m\n\u001b[0;32m     39\u001b[0m le1 \u001b[39m=\u001b[39m OrdinalEncoder(handle_unknown\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39muse_encoded_value\u001b[39m\u001b[39m'\u001b[39m, unknown_value\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m---> 40\u001b[0m dataframe[\u001b[39m\"\u001b[39m\u001b[39mdom\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m le1\u001b[39m.\u001b[39;49mfit_transform(dataframe[\u001b[39m\"\u001b[39;49m\u001b[39mdom\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mvalues\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m,\u001b[39m1\u001b[39;49m))\n\u001b[0;32m     42\u001b[0m le2 \u001b[39m=\u001b[39m OrdinalEncoder(handle_unknown\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39muse_encoded_value\u001b[39m\u001b[39m'\u001b[39m, unknown_value\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     43\u001b[0m dataframe[\u001b[39m\"\u001b[39m\u001b[39mtags\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m le2\u001b[39m.\u001b[39mfit_transform(dataframe[\u001b[39m\"\u001b[39m\u001b[39mtags\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\augus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 142\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    143\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    144\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    145\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    147\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    148\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\augus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:859\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    855\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    857\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    858\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[0;32m    860\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    861\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\augus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:1258\u001b[0m, in \u001b[0;36mOrdinalEncoder.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1251\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m   1252\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39munknown_value should only be set when \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1253\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mhandle_unknown is \u001b[39m\u001b[39m'\u001b[39m\u001b[39muse_encoded_value\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1254\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgot \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39munknown_value\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1255\u001b[0m     )\n\u001b[0;32m   1257\u001b[0m \u001b[39m# `_fit` will only raise an error when `self.handle_unknown=\"error\"`\u001b[39;00m\n\u001b[1;32m-> 1258\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, handle_unknown\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle_unknown, force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m   1260\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_unknown \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39muse_encoded_value\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1261\u001b[0m     \u001b[39mfor\u001b[39;00m feature_cats \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcategories_:\n",
      "File \u001b[1;32mc:\\Users\\augus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:74\u001b[0m, in \u001b[0;36m_BaseEncoder._fit\u001b[1;34m(self, X, handle_unknown, force_all_finite, return_counts)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_n_features(X, reset\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     73\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_feature_names(X, reset\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m---> 74\u001b[0m X_list, n_samples, n_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_X(\n\u001b[0;32m     75\u001b[0m     X, force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite\n\u001b[0;32m     76\u001b[0m )\n\u001b[0;32m     77\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_ \u001b[39m=\u001b[39m n_features\n\u001b[0;32m     79\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcategories \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\augus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:46\u001b[0m, in \u001b[0;36m_BaseEncoder._check_X\u001b[1;34m(self, X, force_all_finite)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[39mPerform custom check_array:\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[39m- convert list of strings to object dtype\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     42\u001b[0m \n\u001b[0;32m     43\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mhasattr\u001b[39m(X, \u001b[39m\"\u001b[39m\u001b[39miloc\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mgetattr\u001b[39m(X, \u001b[39m\"\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m0\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m):\n\u001b[0;32m     45\u001b[0m     \u001b[39m# if not a dataframe, do normal check_array validation\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m     X_temp \u001b[39m=\u001b[39m check_array(X, dtype\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite)\n\u001b[0;32m     47\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(X, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m np\u001b[39m.\u001b[39missubdtype(X_temp\u001b[39m.\u001b[39mdtype, np\u001b[39m.\u001b[39mstr_):\n\u001b[0;32m     48\u001b[0m         X \u001b[39m=\u001b[39m check_array(X, dtype\u001b[39m=\u001b[39m\u001b[39mobject\u001b[39m, force_all_finite\u001b[39m=\u001b[39mforce_all_finite)\n",
      "File \u001b[1;32mc:\\Users\\augus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:931\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    929\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n\u001b[0;32m    930\u001b[0m     \u001b[39mif\u001b[39;00m n_samples \u001b[39m<\u001b[39m ensure_min_samples:\n\u001b[1;32m--> 931\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    932\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m sample(s) (shape=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) while a\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    933\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m minimum of \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m is required\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    934\u001b[0m             \u001b[39m%\u001b[39m (n_samples, array\u001b[39m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[0;32m    935\u001b[0m         )\n\u001b[0;32m    937\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_features \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m    938\u001b[0m     n_features \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "def demandeFavoriteOrNot(nomImage,typeEnjoyer=\"likeAll\"):\n",
    "    jsonMetaDF = pd.read_json(\"metaDataJson.json\")\n",
    "   \n",
    "    if typeEnjoyer ==\"likeAll\":\n",
    "        return 'Favorite'\n",
    "    elif typeEnjoyer ==\"dogEnjoyer\":\n",
    "        print(nomImage)\n",
    "        #print(jsonMetaDF[nomImage])\n",
    "        if \"Dog\" in jsonMetaDF[nomImage][\"tags\"]:\n",
    "            return 'Favorite'\n",
    "        else:\n",
    "            return 'NotFavorite'\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def cyclePropositionImage(numUser,typeEnjoyer):\n",
    "    userId=\"user\"+str(numUser)\n",
    "    jsonMetaDF = pd.read_json(\"metaDataJson.json\")\n",
    "    jsonUserDF=pd.read_json(\"jsonUser.json\")\n",
    "    imageDonee=[]\n",
    "    imagePasDonnes=[]\n",
    "    imageAdonne=1\n",
    "    for image in jsonMetaDF:\n",
    "        if image not in jsonUserDF[userId][\"images\"]:\n",
    "            \n",
    "            ana=analyseGlobal(numUser,image)\n",
    "            if ana==('Favorite'):\n",
    "                imageDonee.append(image)\n",
    "            else:\n",
    "                imagePasDonnes.append(image)\n",
    "    \n",
    "    if imageDonee!=[]:\n",
    "        imageAdonne=random.choice(imageDonee)\n",
    "        print(imageAdonne)\n",
    "        jsonUserDF[userId][\"images\"].append(imageAdonne)\n",
    "    else:\n",
    "        imageAdonne=random.choice(imagePasDonnes)\n",
    "        jsonUserDF[userId][\"images\"].append(imagePasDonnes)\n",
    "    #print(imageAdonne)\n",
    "    res = demandeFavoriteOrNot(numUser,imageAdonne,typeEnjoyer)\n",
    "    \n",
    "    if res=='Favorite':\n",
    "        jsonUserDF[userId][\"result\"].append(1)\n",
    "    elif res=='NotFavorite':\n",
    "        jsonUserDF[userId][\"result\"].append(0)\n",
    "    else:\n",
    "        print(\"Error : demandeFavoriteOrNot does not return expected results\") \n",
    "    print(jsonUserDF)\n",
    "    jsonUserDF.to_json(\"jsonUser.json\",orient='columns',indent=4)               \n",
    "\n",
    "cyclePropositionImage(6,\"dogEnjoyer\")\n",
    "\n",
    "def testNcycle(N):\n",
    "    for i in range(N):\n",
    "        cyclePropositionImage(1,\"dogEnjoyer\")\n",
    "        analyseGlobal(1,3)\n",
    "        #cyclePropositionImage(2,\"likeAll\")\n",
    "        #analyseGlobal(3,9)\n",
    "#testNcycle(9)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brouillon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'numUser' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-1a980af361ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mjsonUser\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"jsonUser.json\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnumUser\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mjsonMeta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"metaDatajson.json\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcouleurs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdataArray\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mjsonMeta\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'numUser' is not defined"
     ]
    }
   ],
   "source": [
    " \n",
    "jsonUser=json.load(open(\"jsonUser.json\"))[numUser]\n",
    "jsonMeta=json.load(open(\"metaDatajson.json\"))\n",
    "couleurs=[]\n",
    "dataArray=[]\n",
    "for image in jsonMeta:\n",
    "    if image in jsonUser[\"data\"][\"image\"]:\n",
    "    #image correspond maintenant aux informations des images testees\n",
    "        L=[]\n",
    "        dataImage=[]\n",
    "        if jsonMeta[image][\"tags\"]==[]:\n",
    "            dataImage.append(None)\n",
    "        else:\n",
    "            dataImage.append(jsonMeta[image][\"tags\"])\n",
    "        dataImage.append(jsonMeta[image][\"orientation\"])\n",
    "        dataImage.append(jsonMeta[image][\"width\"])\n",
    "\n",
    "        for couleur in jsonMeta[image][\"couleurs\"]:\n",
    "            for valeurRBG in couleur:\n",
    "                L.append(valeurRBG)\n",
    "        dataArray.append(dataImage)\n",
    "        couleurs.append(L)\n",
    "print(dataArray)\n",
    "numarray=np.array(couleurs)\n",
    "like=np.array(jsonUser[\"data\"][\"resultat\"])\n",
    "    \n",
    "#modele des couleurs\n",
    "percep = Perceptron(max_iter=1000)\n",
    "percep.fit(numarray, like)\n",
    "    \n",
    "\n",
    "#modele arbre de decision generale\n",
    "dataFrame = pd.DataFrame(dataArray, columns=[\"tags\", \"orientation\", \"mode\"])\n",
    "likeFrame=pd.DataFrame(like,columns=['like'])\n",
    "\n",
    "\n",
    "le1 = LabelEncoder()\n",
    "dataFrame['tags'] = le1.fit_transform(dataFrame['tags'])\n",
    "\n",
    "le2 = LabelEncoder()\n",
    "dataFrame['orientation'] = le2.fit_transform(dataFrame['orientation'])\n",
    "\n",
    "le3 = LabelEncoder()\n",
    "dataFrame['mode'] = le3.fit_transform(dataFrame['mode'])\n",
    "\n",
    "le4 = LabelEncoder()\n",
    "likeFrame['like'] = le4.fit_transform(likeFrame['like'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update user preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'image72'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\augus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\augus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\augus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'image72'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 49\u001b[0m\n\u001b[0;32m     46\u001b[0m                f\u001b[39m.\u001b[39mwrite(jsonUserStr)\n\u001b[0;32m     47\u001b[0m                f\u001b[39m.\u001b[39mclose()  \n\u001b[1;32m---> 49\u001b[0m userPreferences() \u001b[39m# Updates all user preferences\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[52], line 33\u001b[0m, in \u001b[0;36muserPreferences\u001b[1;34m(all, user)\u001b[0m\n\u001b[0;32m     31\u001b[0m colorF \u001b[39m=\u001b[39m []\n\u001b[0;32m     32\u001b[0m \u001b[39mfor\u001b[39;00m image \u001b[39min\u001b[39;00m likedImages :\n\u001b[1;32m---> 33\u001b[0m      ori\u001b[39m.\u001b[39mappend(jsonMetaDF\u001b[39m.\u001b[39;49mloc[\u001b[39m\"\u001b[39;49m\u001b[39morientation\u001b[39;49m\u001b[39m\"\u001b[39;49m][image])\n\u001b[0;32m     34\u001b[0m      siz\u001b[39m.\u001b[39mappend(jsonMetaDF\u001b[39m.\u001b[39mloc[\u001b[39m\"\u001b[39m\u001b[39msize\u001b[39m\u001b[39m\"\u001b[39m][image])\n\u001b[0;32m     35\u001b[0m      tagF\u001b[39m.\u001b[39mappend(jsonMetaDF\u001b[39m.\u001b[39mloc[\u001b[39m\"\u001b[39m\u001b[39mtags\u001b[39m\u001b[39m\"\u001b[39m][image])\n",
      "File \u001b[1;32mc:\\Users\\augus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    978\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[0;32m    980\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m--> 981\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[0;32m    983\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m    984\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m    985\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    986\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\augus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\series.py:1089\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1086\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[0;32m   1088\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1089\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[0;32m   1090\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
      "File \u001b[1;32mc:\\Users\\augus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'image72'"
     ]
    }
   ],
   "source": [
    "user = \"user0\" #Select user\n",
    "\n",
    "def userPreferences(all = 1, user = None):\n",
    "\n",
    "     # Get ima\n",
    "     jsonMetaDF = pd.read_json(\"metaDataJson.json\")\n",
    "\n",
    "     # Get user like\n",
    "     userDF = pd.read_json(\"jsonUser.json\")\n",
    "\n",
    "     userlst = []\n",
    "     if all == 1:\n",
    "          for user in userDF:\n",
    "               userlst.append(user)\n",
    "     else:\n",
    "          userlst.append(user)\n",
    "\n",
    "     for user in userlst:\n",
    "          userImages = userDF.loc[\"images\"][user]\n",
    "          userLike = userDF.loc[\"result\"][user]\n",
    "          likedImages = []\n",
    "          for item in userImages :\n",
    "               ind = userImages.index(item)\n",
    "               if userLike[ind] == 1:\n",
    "                    likedImages.append(item)\n",
    "\n",
    "          if len(likedImages) > 0:\n",
    "               ori = []\n",
    "               siz = []\n",
    "               tagF = []\n",
    "               colorF = []\n",
    "               for image in likedImages :\n",
    "                    ori.append(jsonMetaDF.loc[\"orientation\"][image])\n",
    "                    siz.append(jsonMetaDF.loc[\"size\"][image])\n",
    "                    tagF.append(jsonMetaDF.loc[\"tags\"][image])\n",
    "                    colorF.append(jsonMetaDF.loc[\"dom\"][image])\n",
    "\n",
    "               jsonUser=json.load(open(\"jsonUser.json\"))\n",
    "               jsonUser[user][\"orientation\"]=max(ori,key = ori.count)\n",
    "               jsonUser[user][\"size\"]=max(siz,key = siz.count)\n",
    "               jsonUser[user][\"tagFav\"]=max(tagF,key = tagF.count)\n",
    "               jsonUser[user][\"colorFav\"]=max(colorF,key = colorF.count)\n",
    "               \n",
    "               jsonUserStr = json.dumps(jsonUser, indent=4)\n",
    "               f = open(\"jsonUser.json\", \"w\")\n",
    "               f.write(jsonUserStr)\n",
    "               f.close()  \n",
    "\n",
    "userPreferences() # Updates all user preferences"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show User Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user0</th>\n",
       "      <th>user1</th>\n",
       "      <th>user2</th>\n",
       "      <th>user3</th>\n",
       "      <th>user4</th>\n",
       "      <th>user5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>orientation</th>\n",
       "      <td>paysage</td>\n",
       "      <td>paysage</td>\n",
       "      <td>portrait</td>\n",
       "      <td>paysage</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size</th>\n",
       "      <td>Grande</td>\n",
       "      <td>Petite</td>\n",
       "      <td>Moyenne</td>\n",
       "      <td>Grande</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tagFav</th>\n",
       "      <td>[Fruit]</td>\n",
       "      <td>[Fruit]</td>\n",
       "      <td>[Dog]</td>\n",
       "      <td>[Fruit]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>colorFav</th>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "      <td>White</td>\n",
       "      <td>Red</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               user0    user1     user2    user3 user4 user5\n",
       "orientation  paysage  paysage  portrait  paysage            \n",
       "size          Grande   Petite   Moyenne   Grande            \n",
       "tagFav       [Fruit]  [Fruit]     [Dog]  [Fruit]            \n",
       "colorFav         Red      Red     White      Red   NaN   NaN"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def printUserPref(user = None):\n",
    "    if user == None:\n",
    "        userDF = pd.read_json(\"jsonUser.json\")\n",
    "    else :\n",
    "        userDF = pd.read_json(\"jsonUser.json\")\n",
    "        userDF = userDF[user]\n",
    "    return userDF[\"orientation\":\"colorFav\"]\n",
    "\n",
    "printUserPref() # Show all user preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "83f73d5875a575e504ba23451a5997fea59c0c75034f677431fe9f5bc2b0207e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
